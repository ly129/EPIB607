fit
plogis(fit$coefficients[1])
exp(fit$coefficients[1]) / (1+exp(fit$coefficients[1]))
rpois(10, 0.5)
rpois(100, 0.5)
rpois(10, 5)
mean(rpois(10, 5))
mean(rpois(100, 5))
mean(rpois(1000, 5))
source("https://raw.githubusercontent.com/sahirbhatnagar/EPIB607/master/assignments/a6/plot_null_alt.R")
mu0 <- -0.540 # mean under the null
mha <- 0.99*-0.540 # mean under the alternative
s <- 0.0080 # sample/population SD
n <- 5 # sample size
cutoff <- mu0 + qnorm(0.95) * s / sqrt(n)
power_plot(n = n,
s = s,
mu0 = mu0,
mha = mha,
cutoff = cutoff,
alternative = "greater",
xlab = "Freezing point (degrees C)")
power_plot(n = n,
s = s,
mu0 = mu0,
mha = mha,
cutoff = cutoff,
alternative = "equal",
xlab = "Freezing point (degrees C)")
cutoff <- mu0 + qnorm(c(0.025, 0.975)) * s / sqrt(n)
power_plot(n = n,
s = s,
mu0 = mu0,
mha = mha,
cutoff = cutoff,
alternative = "equal",
xlab = "Freezing point (degrees C)")
mha <- 0.998*-0.540 # mean under the alternative
s <- 0.0080 # sample/population SD
n <- 5 # sample size
cutoff <- mu0 + qnorm(c(0.025, 0.975)) * s / sqrt(n)
power_plot(n = n,
s = s,
mu0 = mu0,
mha = mha,
cutoff = cutoff,
alternative = "equal",
xlab = "Freezing point (degrees C)")
power.t.test(delta = abs(-0.540-0.998*-.540))
abs(-0.540-0.998*-.540)
power.t.test(delta = abs(-0.540-0.998*-.540), power = 0.80)
power.t.test(delta = abs(-0.540-0.998*-.540), power = 0.80, sd = 0.0080)
power.t.test(delta = abs(-0.540-0.998*-.540), power = 0.80, sd = 0.0080, type = "one")
pacman::p_load(manipulate) # or library(manipulate)
mu0 <- -0.540 # mean under the null
mha <- 0.998*-0.540 # mean under the alternative
s <- 0.0080
n <- 5
cutoff <- mu0 + qnorm(c(0.025, 0.95) * s / sqrt(n)
cutoff <- mu0 + qnorm(c(0.025, 0.95) * s / sqrt(n))
cutoff <- mu0 + qnorm(c(0.025, 0.95)) * s / sqrt(n)
manipulate::manipulate(
power_plot(n = sample_size, s = sample_sd,
mu0 = mu0, mha = mha,
cutoff = cutoff,
alternative = "equal",
xlab = "Freezing point (degrees C)"),
sample_size = manipulate::slider(5, 100),
sample_sd = manipulate::slider(0.001, 0.01, initial = 0.008))
manipulate::manipulate(
power_plot(n = sample_size, s = sample_sd,
mu0 = mu0, mha = mha,
cutoff = cutoff,
alternative = "equal",
xlab = "Freezing point (degrees C)"),
sample_size = manipulate::slider(5, 500),
sample_sd = manipulate::slider(0.001, 0.01, initial = 0.008))
power_plot(n = n,
s = s,
mu0 = mu0,
mha = mha,
cutoff = cutoff,
alternative = "equal",
xlab = "Freezing point (degrees C)")
power.t.test(delta = abs(-0.540-0.998*-.540), power = 0.80, sd = 0.0080, type = "one")
(qnorm(0.975) + qnorm(0.84))^2  * (0.0080/abs(-0.540-0.998*-.540))^2
qnorm(0.8)
(qnorm(0.95) + qnorm(0.84))^2  * (0.0080/abs(-0.540-0.998*-.540))^2
qnorm(0.4)
qnorm(0.84)
qnorm(0.8)
(qnorm(0.975) + qnorm(0.8))^2  * (0.0080/abs(-0.540-0.998*-.540))^2
power.t.test(delta = abs(-0.540-0.998*-.540), power = 0.80, sd = 0.0080, type = "one")
(qnorm(0.975) + qnorm(0.8))^2  * (0.0080/abs(-0.540-0.998*-.540))^2
qnorm(0.8)
qnorm(0.975)
abs(-0.540-0.998*-.540)
(qnorm(0.975) + qnorm(0.8))^2  * (0.0080/abs(-0.540-0.998*-.540))^2
qnorm(0.8)
n-1
(qt(0.975, n-1) + qt(0.8, n-1))^2  * (0.0080/abs(-0.540-0.998*-.540))^2
(qnorm(0.975) + qnorm(0.8))^2  * (0.0080/abs(-0.540-0.998*-.540))^2
(qnorm(0.975) + qnorm(0.8))^2
power.t.test(delta = abs(-0.540-0.998*-.540), power = 0.80, sd = 0.0080, type = "two")
power.t.test(delta = abs(-0.540-0.998*-.540), power = 0.80, sd = 0.0080, type = "one", alternative = "two")
power.t.test(delta = abs(-0.540-0.998*-.540), power = 0.80, sd = 0.0080, type = "one",
alternative = "one")
(qnorm(0.95) + qnorm(0.8))^2  * (0.0080/abs(-0.540-0.998*-.540))^2
pbinom(140, 145, 0.9, lower.tail = F)
pnorm(140, mean = 145*.9, sd = sqrt(145*0.9*0.1), lower.tail = F)
145*0.9
145*0.1
pnorm(140, mean = 145*.9, sd = sqrt(145*0.9*0.1), lower.tail = F)
pbinom(140, 145, 0.9, lower.tail = F)
pnorm(141, mean = 145*.9, sd = sqrt(145*0.9*0.1), lower.tail = F)
pbinom(140, 145, 0.9, lower.tail = F)
pnorm(141, mean = 145*.9, sd = sqrt(145*0.9*0.1), lower.tail = F)
pnorm(141-.5, mean = 145*.9, sd = sqrt(145*0.9*0.1), lower.tail = F)
pnorm(141+.5, mean = 145*.9, sd = sqrt(145*0.9*0.1), lower.tail = F)
pnorm(140, mean = 145*.9, sd = sqrt(145*0.9*0.1), lower.tail = F)
binom.test(95, 100, p=0.9)
binom.test(95, 100, p = 0.9)
100*.1
100*.9
binom.test(95, 100, p = 0.9)
binom.test(95, 100, p = 0.8)
22/30
20/3
20/25
binom.test(20,25)
wilsonCP=TRUE
if(wilsonCP){
nn=c(5,20); yy=c(4,16)
par(mfrow=c(1,2),mar = c(2.5,0.1,0.1,0.1) )
for(J in 1:2){
y=yy[J] ; n=nn[J]
p.O=y/n
z=1.96
( p.L = round((p.O + z^2/(2*n) - 1.96*sqrt(p.O*(1-p.O)/n +z^2/(4*n^2))) / ( 1+ z^2/n),6 ))
p.L + 1.96 * sqrt(p.L*(1-p.L)/n)
( p.U = round((p.O + z^2/(2*n) + 1.96*sqrt(p.O*(1-p.O)/n +z^2/(4*n^2))) / ( 1+ z^2/n),4 ))
p.U - 1.96 * sqrt(p.U*(1-p.U)/n)
pi=seq(0,1,0.01)
Y = max(dnorm(pi,mean=p.U,
sd=sqrt(p.U*(1-p.U)/n) )
)
YLIM=c(-1.2,1.25)*Y
# blue
SE = sqrt(p.L*(1-p.L)/n)
h=dnorm(pi,mean=p.L,sd=SE)
H = max(h)
plot(c(0,1),c(0,5),col="white",
ylim=YLIM,xlim=c(-0.05,1.01),
yaxt="n")
points(p.O,-0.1*H,cex=0.75,pch=19)
segments(0,0,1,0,lwd=0.25)
arrows(p.L,0,
p.L,-0.2*max(h),length=0.06,
angle=25,col="blue",lwd=1.5)
text(p.L,-0.35*max(h),
expression(P[L]),
adj=c(0.5,1),col="blue")
txt="4/5" ; if(J==2) txt="16/20"
text(p.O,-0.35*max(h),txt,adj=c(0.5,1))
#text(p.L,-0.22*max(h),"0.376",adj=c(0.5,1),col="blue")
lines(pi,h,col="blue")
#segments(p.L,   0.6*max(h),
#         p.L+SE,0.6*max(h),col="blue")
#text(p.L + SE/2,0.6*max(h),
#expression( paste("SE = ",sqrt(over(0.376(1-0.376),5)) ) ),
#adj=c(0.5,1.25),col="blue",cex=0.75)
arrows(p.L,  -0.2*max(h),
p.O,  -0.2*max(h),col="blue",
length=0.08,angle=35,lwd=2)
#text( (p.L + p.O)/2,-0.13*max(h),
#"1.96 x SE",adj=c(0.5,1),col="blue")
tail=seq(p.O,1,length.out=50)
h=dnorm(tail,mean=p.L,sd=SE)
polygon(c(p.O,tail,1),c(0,h,0),col="blue", border=NA)
# red
SE.U = sqrt(p.U*(1-p.U)/n)
arrows(p.U,0,
p.U,-0.2*H,length=0.06,angle=25,col="red")
text(p.U,-0.35*H,
expression(P[U]),
adj=c(0.5,1),col="red")
#text(p.U,-0.22*H,"0.864",adj=c(0.5,1),col="red")
h = dnorm(pi,mean=p.U,sd=SE.U)
HH= max(h)
lines(pi[60:101], h[60:101],col="red")
#segments(p.U,     0.6*max(h),
#        p.U-SE.U,0.6*max(h),col="red")
#text(p.U,0.58*max(h),
#expression( paste("SE = ",sqrt(over(0.864(1-0.864),5)) ) ),adj=c(1,1),col="red",cex=0.65)
tail=seq(0.6,p.O,length.out=50)
h=dnorm(tail,mean=p.U,sd=SE.U)
polygon(c(0.6,tail,p.O),c(0,h,0),col="red", border=NA)
arrows(p.U,  -0.2*H,
p.O,  -0.2*H,col="red",
length=0.08,angle=35,lwd=2)
#text( (p.U + p.O)/2,-0.13*H,
#"1.96 x SE",adj=c(0.5,1),col="red",cex=0.75)
text(0.7,H/6,"2.5%",col="red",cex=0.8)
#segments(0.7,H/8 , p.O,0,col="red")
text(0.9,H/6,"2.5%",col="blue",cex=0.8)
#segments(0.9,H/8 , p.O,0,col="blue")
txt="WILSON 1927. CI for  proportion P, based on observed sample proportion p.
Probable Inference (USUAL). Say we observe a certain proportion, p,
in a sample of n. We compute an interval using a statistical model
(binomial or Gaussian) that uses (the statistic) p as the parameter
for the sampling distribution.
It is common to say that the probability that the true proportion, P say,
lies below/above the 2.5/97.5-%ile [of this sampling distribution
centered on p] is 0.05."
if(J==2)
txt="WILSON 1927 (continued...)
Strictly speaking, this statement is elliptical. Really the chance that
P lies outside a specified range is either 0 or 1. It is the observed
proportion p which has a greater or less chance of lying within a certain
interval of P. If the observer was unlucky to have observed a rare
event and to have based his inference thereon, he may be fairly wide
of the mark.
Probable Inference (IMPROVED). A better way is to reason:
There is some [true] P. Consider 2 scenarios:"
text(-0.045,1.28*Y,txt,cex=0.7,
adj=c(0,1), col="grey35" )
text(p.U,0.65*HH,
"p --- P ('p is an under-estimate'):
p landed at the 2.5%-ile of this
sampling distribution (Distrn):
p = qDistrn(0.025,
prob = P.Upper)
--> solve for P.Upper",
cex=0.6, adj=c(1,1),col="red" )
text(p.L,(0.55-(J==2)/20)*HH,
"P---p ('p is an over-estimate'):
p landed at the 97.5%-ile of this
sampling distribution (Distrn):
p = qDistrn(0.975,
prob = P.Lower)
--> solve for P.Lower",
cex=0.6, adj=c(1,1),col="blue" )
text(-0.045,-0.03*HH,
"Wilson used 2 Gaussian
sampling distributions",
cex=0.75, adj=c(0,1))
text(-0.045,-0.3*HH,
"Clopper-Pearson (1934)
used 2 Binomial distributions",
cex=0.75, adj=c(0,1))
yo=-1.07*Y; dy=0.7*Y ; dx=0.003
binom.test(16,20)
if(J==1) {P.L=0.2835821 ; P.U=0.9949492}
if(J==2) {P.L=0.563386  ; P.U=0.942666}
segments(0,yo,1,yo)
text(p.O,yo-0.10*Y,"p",adj=c(0.5,1))
arrows(P.L,yo-0.05*Y,P.L,yo,
col="blue", length=0.07,angle=25)
text(P.L,yo-0.10*Y,expression(P[L]),
adj=c(0.5,1),col="blue")
h= dy*dbinom(0:n,n,P.L)
segments((0:n)/n +dx, yo,
(0:n)/n +dx, yo+h,
col="blue",lwd=2)
txt=
"dbinom(0:5, size=5,
prob=0.283)"
if(J==2) txt=
"dbinom(0:20, size=20,
prob=0.563)"
Yy = yo+0.4*Y
text(P.L-ifelse(J==2, 0.1,0),Yy,txt,
col="blue",adj=c(1,1),cex=0.65,family="mono")
txt=expression(paste(Sigma,"[4:5]"))
if(J==2)txt=expression(paste(Sigma,"[16:20]"))
Yy = yo+0.25*Y
text(p.O*1.02,Yy,txt,
col="blue",adj=c(0,1),cex=0.6,family="mono")
arrows(P.U,yo-0.05*Y,P.U,yo,
col="red", length=0.07,angle=25)
text(P.U,yo-0.10*Y,expression(P[U]),
adj=c(0.5,1),col="red")
h= dy*dbinom(0:n,n,P.U)
segments((0:n)/n -dx , yo,
(0:n)/n -dx,  yo+h,
col="red",lwd=2)
txt=
expression(paste(Sigma,"[0:4]"))
if(J==2) txt=
expression(paste(Sigma,"[0:16]"))
Yy = yo+0.25*Y
text(0.98*p.O,Yy,txt,
col="red",adj=c(1,1),family="mono",cex=0.6)
txt=
"dbinom(0:5, size=5,
prob=0.995)"
if(J==2) txt=
"dbinom(0:20, size=20,
prob=0.943)"
Yy = yo+0.4*Y
text(0.99*P.U+ifelse(J==2,0.1,0),Yy,txt,
col="red",adj=c(1,1),family="mono",cex=0.65)
points(p.O,yo-0.05*Y,cex=0.75,pch=19)
# text( sum(dbinom(4:5,5,0.283))
text(0.98*p.O,yo+0.18*Y,"2.5%",col="red",
cex=0.8,adj=c(1,1))
text(1.02*p.O,yo+0.18*Y,"2.5%",col="blue",
cex=0.8,adj=c(0,1))
} # end J
} # end wilsonCP
qnorm(p = c(0.025, 0.975), mean = 65.3, sd = 1.25)
mosaic::xqnorm(p = c(0.025, 0.975), mean = 65.3, sd = 1.25)
mosaic::xqnorm(p = c(0.025, 0.975), mean = 65.3, sd = 1.25, return = "plot")
mosaic::xqnorm(p = c(0.025, 0.975), mean = 65.3, sd = 1.25, return = "plot") +
theme_bw()
library(mosaic)
mosaic::xqnorm(p = c(0.025, 0.975), mean = 65.3, sd = 1.25, return = "plot") +
theme_bw()
gg_sy <- theme(legend.position = "bottom", axis.text = element_text(size = 20),
axis.title = element_text(size = 20),
legend.text = element_text(size = 20),
legend.title = element_text(size = 20))
library(mosaic)
gg_sy <- theme(legend.position = "bottom", axis.text = element_text(size = 20),
axis.title = element_text(size = 20),
legend.text = element_text(size = 20),
legend.title = element_text(size = 20))
mosaic::xqnorm(p = c(0.025, 0.975), mean = 65.3, sd = 1.25, return = "plot") +
theme_bw() + gg_sy
library(mosaic)
gg_sy <- theme(axis.text = element_text(size = 20),
axis.title = element_text(size = 20),
legend.text = element_text(size = 20),
legend.title = element_text(size = 20))
mosaic::xqnorm(p = c(0.025, 0.975), mean = 65.3, sd = 1.25, return = "plot") +
theme_bw() + gg_sy
gg_sy <- theme(legend.position = "bottom", axis.text = element_text(size = 20),
axis.title = element_text(size = 20),
legend.text = element_text(size = 20),
legend.title = element_text(size = 20))
mosaic::xqnorm(p = c(0.025, 0.975), mean = 65.3, sd = 1.25, return = "plot") +
theme_bw() + gg_sy
mosaic::xqnorm(p = c(0.025, 0.975), mean = 65.3, sd = 1.25, return = "plot") +
theme_bw() + gg_sy + scale_fill_grey()
mosaic::xqnorm(p = c(0.025, 0.975), mean = 65.3, sd = 1.25, return = "plot") +
theme_bw() + gg_sy + scale_fill_manual(values = c("grey60","black", "grey60"))
mosaic::xqnorm(p = c(0.025, 0.975), mean = 65.3, sd = 1.25, return = "plot") +
theme_bw() + gg_sy + scale_fill_manual(values = c("black","grey60", "black"))
mosaic::xqnorm(p = c(0.025, 0.975), mean = 65.3, sd = 1.25, return = "plot") +
theme_bw() + gg_sy + scale_fill_manual(values = c("black","grey60", "black")) +
scale_x_continuous()
mosaic::xqnorm(p = c(0.025, 0.975), mean = 65.3, sd = 1.25, return = "plot") +
theme_bw() + gg_sy + scale_fill_manual(values = c("black","grey60", "black")) +
scale_x_continuous(breaks = seq(60, 71, 1))
mosaic::xqnorm(p = c(0.025, 0.975), mean = 65.3, sd = 1.25, return = "plot") +
theme_bw() + gg_sy + scale_fill_manual(values = c("black","grey60", "black")) +
scale_x_continuous(breaks = seq(59, 71, 1))
mosaic::xqnorm(p = c(0.025, 0.975), mean = 65.3, sd = 1.25, return = "plot") +
theme_bw() + gg_sy + scale_fill_manual(values = c("black","grey60", "black")) +
scale_x_continuous(breaks = seq(59, 71, .5))
df <- as.data.frame(rbind(
c("1. Final exam date: December 6th, Otto MAASS 112 (cap 220) available from 9am-6pm "),
c("2. [Inference about a population rate](https://github.com/sahirbhatnagar/EPIB607/raw/master/slides/one_sample_rate/EPIB607_one_sample_rate.pdf)")
))
df %>% kable(col.names = NULL) %>%
kable_styling(bootstrap_options = c("striped", "hover"))
library(mosaic)
df <- as.data.frame(rbind(
c("1. Final exam date: December 6th, Otto MAASS 112 (cap 220) available from 9am-6pm "),
c("2. [Inference about a population rate](https://github.com/sahirbhatnagar/EPIB607/raw/master/slides/one_sample_rate/EPIB607_one_sample_rate.pdf)")
))
df %>% kable(col.names = NULL) %>%
kable_styling(bootstrap_options = c("striped", "hover"))
mosaic::xqpois(c(0.025, 0.975), lambda = 6)
mosaic::xqpois(c(0.025, 0.975), lambda = 60)
mosaic::xqpois(c(0.025, 0.975), lambda = 70)
mosaic::xqpois(c(0.025, 0.975), lambda = 100)
mosaic::xqpois(c(0.025, 0.975), lambda = 120)
mosaic::xqpois(c(0.025, 0.975), lambda = 150)
174-126
manipulate::manipulate(
mosaic::xqpois(c(0.025, 0.975), lambda = LAMBDA),
LAMBDA = manipulate::slider(1, 200, step = 1))
poisson.test(150)
mosaic::xqpois(c(0.025, 0.975), lambda = 150)
manipulate::manipulate(
mosaic::xqpois(c(0.025, 0.975), lambda = LAMBDA),
LAMBDA = manipulate::slider(1, 200, step = .1))
# upper limit --> lower tail needs 2.5%
manipulate::manipulate(
mosaic::xppois(6, lambda = LAMBDA),
LAMBDA = manipulate::slider(0.01, 20, step = 0.01))
mosaic::xqnorm(c(0.025, 0.975), mean = 30, sd = sqrt(30))
qgamma(c(0.025, 0.975), c(30,31))
mosaic::xqnorm(c(0.025, 0.975), mean = 100, sd = sqrt(100))
qgamma(c(0.025, 0.975), c(100,101))
mosaic::xqnorm(c(0.025, 0.975), mean = 150, sd = sqrt(150))
qgamma(c(0.025, 0.975), c(150,151))
16/20
library(mosaic)
mosaicData::HELPrct
mosaicData::HELPrct %>% colnames
mosaicData::HELPrct %>% head
dt <- mosaicData::HELPrct
dput(colnames(dt))
dt
dt$sexrisk %>% table
dt <- mosaicData::HELPrct[, c("id","age", "cesd","substance","mcs","sexrisk")]
dt
knitr::kable(head(dt))
library(mosaic)
dt <- mosaicData::HELPrct[, c("id","age", "cesd","substance","mcs","sexrisk")]
knitr::kable(head(dt))
data("HELPfull")
knitr::kable(dt[1:5,])
summary(dt)
range(dt$cesd)
range(dt$mcs)
120/18
pbinom(q = 13, 20, 0.5, lower.tail = F)
pbinom(q = 12, 20, 0.5, lower.tail = F)
fit <- glm(cbind(13,7) ~ 1, family = binomial)
summary(fit)
binom.test(13,20)
confint(git)
confint(fit)
plogis(confint(fit))
binom.test(13,20, method = "Clopper")
pbinom(0.8460908, 20, 0.5, lower.tail = F)
qbinom(0.975, 20, 0.8460908)
qbinom(0.025, 20, 0.4078115)
pbinom(12, 20, 0.5, lower.tail = FALSE)
pbinom(12, 20, 0.5, lower.tail = FALSE)*2
(1-pbinom(12, 20, 0.5, lower.tail = FALSE))
(1-pbinom(12, 20, 0.5))
(1-pbinom(12, 20, 0.5))*2
qnorm(c(0.025, 0.975), mean = 13/20, sd = sqrt((13/20)*(7/20)/20))
binom.test(13,20, method = "Wald")
mosaic::binom.test(13,20, ci.method = "Wald")
qnorm(c(0.025, 0.975), mean = 13/20, sd = sqrt((13/20)*(7/20)/20))
pbinom(12, 20, 0.5, lower.tail = FALSE)*2
SEp <- sqrt(0.65*0.35/20)
zstat <- (0.65 - 0.5) / SEp
pnorm(zstat, lower.tail = FALSE) * 2
SEp <- sqrt(0.5*0.5/20) # under the null
zstat <- (0.65 - 0.5) / SEp
pnorm(zstat, lower.tail = FALSE) * 2
zstat
SEp <- sqrt(0.5*0.5/20) # under the null
zstat <- (0.65 - 0.5) / SEp
pnorm(1.34, lower.tail = FALSE) * 2
3*96*3+1
qnorm(0.025)
6+5+6+5+6+7+6+5+8+6+6+10+3+4+6+6
#one sided test, less than
n_step <- 25
s_step <- 60
mu_step <- 500
se_step <- s_step/sqrt(n_step)
#rearrage t = (ybar-mu)/SE to find ybar
min_crit_step <- qt(0.01, df = 24, lower.tail=TRUE)*se_step + mu_step
min_crit_step
source("https://raw.githubusercontent.com/sahirbhatnagar/EPIB607/master/assignments/a6/plot_null_alt.R")
mu0 <- 500
mha <- 470
cutoff <- mu0 + qnorm(0.01) * step_s / sqrt(step_n)
source("https://raw.githubusercontent.com/sahirbhatnagar/EPIB607/master/assignments/a6/plot_null_alt.R")
step_s <- 60
step_n <- 25
step_critv <- xqnorm(p = 0.01, mean = 500, sd = step_s/sqrt(step_n))
step_critvdisp <- round(step_critv, 2)
step_prob <- round(xpnorm(q = step_critv, mean = 470, sd = step_s/sqrt(step_n)), 2)
mu0 <- 500
mha <- 470
## ---- Question-1 ------------------------------------------------------------
library(mosaic)
step_s <- 60
step_n <- 25
step_critv <- xqnorm(p = 0.01, mean = 500, sd = step_s/sqrt(step_n))
step_critvdisp <- round(step_critv, 2)
step_prob <- round(xpnorm(q = step_critv, mean = 470, sd = step_s/sqrt(step_n)), 2)
mu0 <- 500
mha <- 470
cutoff <- mu0 + qnorm(0.01) * step_s / sqrt(step_n)
source("https://raw.githubusercontent.com/sahirbhatnagar/EPIB607/master/assignments/a6/plot_null_alt.R")
power_plot(n = 41, s = step_s,
mu0 = mu0,
mha = mha,
cutoff = mu0 + qnorm(0.01) * step_s / sqrt(41),
alternative = "less",
xlab = "Steps")
## ....or just calculate it
step_nforpower <- ceiling((-xqnorm(p = 0.01) + xqnorm(p = 0.8))^2 * (step_s/(470-500))^2)
step_nforpower
power_plot(n = 41, s = step_s,
mu0 = mu0,
mha = mha,
cutoff = mu0 + qnorm(0.01) * step_s / sqrt(41),
alternative = "less",
xlab = "Steps")
## ---- Question-1 ------------------------------------------------------------
library(mosaic)
step_s <- 60
step_n <- 25
step_critv <- xqnorm(p = 0.01, mean = 500, sd = step_s/sqrt(step_n))
step_critvdisp <- round(step_critv, 2)
step_prob <- round(xpnorm(q = step_critv, mean = 470, sd = step_s/sqrt(step_n)), 2)
step_prob
power = pnorm(-.5366, mean = -.5346, sd = 0.008/sqrt(15), lower.tail= FALSE)
power
6+6+5+6+6+7+
3+6+5+8+8+10+6+10
