\documentclass{beamer}

\usepackage{default}
\usepackage{animate} %need the animate.sty file 
\usepackage{graphicx}
%\graphicspath{{/home/sahir/Dropbox/jobs/laval/minicours/slides/}}
\usepackage{hyperref, url}
%\usepackage[round,sort]{natbib}   % bibliography omit 'round' option if you prefer square brackets
%\bibliographystyle{apalike}
\usepackage{biblatex}
\bibliography{bib.bib}
% Removes icon in bibliography
\setbeamertemplate{bibliography item}[text]

\usepackage[normalem]{ulem}

\setbeamertemplate{theorems}[numbered]



%\newtheorem{prop}{Proposition}
%\newenvironment{theoremc}[1]
%{\begin{shaded}\begin{theorem}[#1]}
%		{\end{theorem}\end{shaded}}
	
%\newtheorem{examplefirst}{Example}
%\newtheorem{examplesecond}{Example}
%\newenvironment<>{examplefirst}[1][]{%
%	\setbeamercolor{block title example}{bg=lightgray}%
%	\begin{example}#2[#1]}{\end{example}}
%\newenvironment<>{examplesecond}[1][]{%
%	\setbeamercolor{block title example}{fg=white,bg=blue!75!black}%
%	\begin{example}#2[#1]}{\end{example}}	

%\usepackage{amsthm}


\usepackage[figurename=Fig.]{caption}
\usepackage{subfig}
\usepackage{tikz, pgfplots,epsfig}
\usetikzlibrary{arrows,shapes.geometric}
\usepackage{color, colortbl,xcolor}
\definecolor{lightgray}{RGB}{200,200,200}
\definecolor{palegray}{RGB}{221,221,221}
\definecolor{myblue}{RGB}{0,89,179}
\usepackage{comment}
\setbeamercolor{frametitle}{fg=myblue}
\setbeamercolor{section in head/foot}{bg=myblue, fg=white}
\setbeamercolor{author in head/foot}{bg=myblue}
\setbeamercolor{date in head/foot}{bg=myblue}

\usepackage{shadethm}
%\colorlet{shadecolor}{blue!15}
\colorlet{shadecolor}{palegray}
%\setlength{\shadeboxrule}{.4pt}

\newshadetheorem{thm}{Theorem}
\newshadetheorem{defm}{Definition}
\newshadetheorem{exm}{Exercise}
\newshadetheorem{remarkm}{Remark}
%\definecolor{shadethmcolor}{HTML}{EDF8FF}
\definecolor{shadethmcolor}{RGB}{221,221,221}
%\definecolor{shaderulecolor}{HTML}{45CFFF}
\definecolor{shaderulecolor}{RGB}{0,89,179}
\setlength{\shadeboxrule}{.4pt}


\usepackage{array}
\newcolumntype{L}{>{\centering\arraybackslash}m{3cm}} % used for text wrapping in ctable
\usepackage{ctable}
\usepackage[utf8]{inputenc}
\usepackage{fontenc}
\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\def\widebar#1{\overline{#1}}
\definecolor{whitesmoke}{rgb}{0.96, 0.96, 0.96}

\usepackage{amssymb}
\usepackage{amsmath}

\usepackage{bm}
\def\transpose{{\sf{T}}}
\def\E{{\skew0\bm{E}}}
\def\Xvec{{\skew0\bm{X}}}
\def\Xveca{{\skew0\bm{X}}_1}
\def\Xvecb{{\skew0\bm{X}}_2}

\def\Yvec{{\skew0\bm{Y}}}
\def\bmY{{\skew0\bm{Y}}}
\def\bmX{{\skew0\bm{X}}}
\def\bmy{{\skew0\bm{y}}}
\def\bmG{{\skew0\bm{G}}}
\def\bmS{{\skew0\bm{S}}}
\def\bmA{{\skew0\bm{A}}}
\def\bmB{{\skew0\bm{B}}}
\def\bmD{{\skew0\bm{D}}}
\def\bmI{{\skew0\bm{I}}}
\def\bmV{{\skew0\bm{V}}}
\def\bmU{{\skew0\bm{U}}}
\def\bv{{\skew0\bm{v}}}
\def\bw{{\skew0\bm{w}}}
\def\bmm{{\skew0\bm{m}}}
\def\bmzero{{\skew0\bm{0}}}
\def\bx{{\skew0\bm{x}}}
\def\xveca{{\skew0\bm{x}}_1}
\def\xvecb{{\skew0\bm{x}}_2}

\def\N{{\skew0\mathcal{N}}}
\def\T{{\small T}}

\def\mvec{{\skew0\bm{m}}}
\def\bmmu{{\skew0\bm{\mu}}}
\def\muvec{{\skew0\bm{\mu}}}
\def\balpha{{\skew0\bm{\alpha}}}
\def\bbeta{{\skew0\bm{\beta}}}
\def\bmtheta{{\skew0\bm{\theta}}}
\def\btheta{{\skew0\bm{\theta}}}

\def\cvec{{\skew0\mathbf{c}}}

\def\Xbar{\overline{X}}

\definecolor{lightgray}{rgb}{0.91,0.91,0.91}
\definecolor{purpleblue}{rgb}{0.50,0.50,1.00}



\usepackage{fontspec}
%\setsansfont{Fira Sans}
%\setmonofont{Fira Mono}
\setsansfont[ItalicFont={Fira Sans Light Italic},BoldFont={Fira Sans},BoldItalicFont={Fira Sans Italic}]{Fira Sans Light}
\setmonofont[BoldFont={Fira Mono Medium}]{Fira Mono}


\setbeamercolor{itemize item}{fg=myblue}
\setbeamertemplate{itemize item}[square]

\setbeamertemplate{navigation symbols}{\usebeamercolor[fg]{title in head/foot}\usebeamerfont{title in head/foot}\insertframenumber}
\setbeamertemplate{footline}{}

\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{exercise}[theorem]{Exercise}

\titlegraphic{\hfill\includegraphics[height=1cm]{mcgill_logo.png}}


%% You also use hyperref, and pick colors 
\hypersetup{colorlinks,citecolor=orange,filecolor=red,linkcolor=brown,urlcolor=blue}

\newcommand {\framedgraphiccaption}[2] {
	\begin{figure}
		\centering
		\includegraphics[width=\textwidth,height=0.8\textheight,keepaspectratio]{#1}
		\caption{#2}
	\end{figure}
}

\newcommand {\framedgraphic}[1] {
	\begin{figure}
		\centering
		\includegraphics[width=\textwidth,height=0.9\textheight,keepaspectratio]{#1}
	\end{figure}
}


\AtBeginSection[]{
	\begin{frame}
		\vfill
		\centering
		\begin{beamercolorbox}[sep=8pt,center,shadow=true,rounded=true]{title}
			\usebeamerfont{title}\insertsectionhead\par%
		\end{beamercolorbox}
		\vfill
	\end{frame}
}

\newcommand\Wider[2][3em]{%
	\makebox[\linewidth][c]{%
		\begin{minipage}{\dimexpr\textwidth+#1\relax}
			\raggedright#2
		\end{minipage}%
	}%
}



\newcommand{\blue}[1]{\textcolor{blue}{#1}}
\newcommand{\red}[1]{\textcolor{red}{#1}}
%\makeatother

\usepackage{xparse}
\NewDocumentCommand\mylist{>{\SplitList{;}}m}
{
	\begin{itemize}
		\ProcessList{#1}{ \insertitem }
	\end{itemize}
}
\NewDocumentCommand\mynum{>{\SplitList{;}}m}
{
	\begin{enumerate}
		\ProcessList{#1}{ \insertitem }
	\end{enumerate}
}
\newcommand\insertitem[1]{\item #1}

\newcommand\FrameText[1]{%
	\begin{textblock*}{\paperwidth}(0pt,\textheight)
		\raggedright #1\hspace{.5em}
\end{textblock*}}


\begin{document}
%\sffamily

<<setup, include=FALSE>>=
rm(list = ls())
library(knitr)
knitr::opts_chunk$set(cache=TRUE, message = FALSE, tidy = FALSE,warning=FALSE, 
echo = FALSE, fig.width = 8, fig.asp = 0.8, 
fig.align = 'center', out.width = "100%", size = 'scriptsize')
# the kframe environment does not work with allowframebreaks, so remove it
knit_hooks$set(document = function(x) {
gsub('\\\\(begin|end)\\{kframe\\}', '', x)
})
pacman::p_load(knitr)

# pacman::p_load(ISLR)
# pacman::p_load(data.table)
# pacman::p_load(rpart)
# pacman::p_load(rpart.plot)
# pacman::p_load(xtable)
# pacman::p_load(ggplot2)
# trop <- RSkittleBrewer::RSkittleBrewer("trop")
# gg_sy <- theme(legend.position = "bottom", axis.text = element_text(size = 20), axis.title = element_text(size = 20), legend.text = element_text(size = 20), legend.title = element_text(size = 20))
@

%\title{Introduction to Regression Trees}
%\author{Sahir Bhatnagar \inst{1}}
%\author[shortname]{Sahir Rai Bhatnagar, PhD Candidate (Biostatistics) }
%\institute[shortinst]{Department of Epidemiology, Biostatistics and Occupational Health}

\title{Inference about a Population Proportion ($\pi$)}
\subtitle{AAO unit 28; Baldi \& Moore, Ch 19}
\author{Sahir Bhatnagar and James Hanley}
\institute{
	EPIB 607\\
	Department of Epidemiology, Biostatistics, and Occupational Health\\
	McGill University\\
	
	\vspace{0.1 in}
	
	\texttt{sahir.bhatnagar@mcgill.ca}\\
	\texttt{\url{https://sahirbhatnagar.com/EPIB607/}}}

%\date

\maketitle

\section{Binomial Model for Sampling Variability of Proportion/Count in a Sample}




\begin{frame}
\frametitle{The Binomial Distribution: what it is}
\small
\begin{itemize}
	\setlength\itemsep{0.5em}
	\item It is the $n+1$ probabilities $p_{0}, p_{1}, ..., p_{y}, ..., p_{n}$ of observing 
	$0, 1, 2, \dots , n$ ``positives''  in \underline{$n$ independent realizations of a Bernoulli random variable} $Y$:
	$$
	Y = \begin{cases}
	1 & P(Y=1) = \pi \\
	0 & P(Y=0) = 1-\pi
	\end{cases}	
	$$
	The number is the sum of $n$ i.i.d. Bernoulli random variables.
	(\emph{such as in SRS of $n$ individuals}) \pause 
	\item Each of the $n$ observed elements is binary (0 or 1) \pause 
	\item There are $2^{n}$ possible \textit{sequences} ... but only $n+1$ possible \textit{values}, 
	i.e. $0/n,\;1/n,\;\dots ,\;n/n$  \emph{(can think of $y$ as sum of $n$ Bernoulli random variables)} 
	\item Note: it is better to work in same scale as the parameter, i.e., in [0,1]. Not the [0,n] count scale.
\end{itemize}
\end{frame}	
	
\begin{frame}
\frametitle{The Binomial Distribution: what it is}
\begin{itemize}
		\setlength\itemsep{0.5em}
	\item Apart from  ($n$), the probabilities $p_{0}$ to $p_{n}$ depend on only 1 parameter:
	\begin{itemize}
		\item the probability that a selected individual will be ``positive''  i.e.,
		\item the proportion of ``positive'' individuals in sampled population
	\end{itemize}

	\item Usually denote this (un-knowable) proportion by $\pi$
	
	\begin{tabular}{lcc}
		\hline
		Author & \textbf{Parameter} & \textbf{Statistic} \\
		\hline
		Clayton \& Hills   & $\pi $ & $p= D/N$ \\
		Hanley et al. & $\pi $ & $p= y/n$ \\
		M\&M, Baldi \& Moore & p &$\hat{p} = y/n$ \\
		Miettinen& P & $p=y/n$ \\
		\hline
	\end{tabular}
	\item
	Shorthand:  $Y\sim\; \textrm{Binomial}(n, \pi)$.
\end{itemize}
\end{frame}


\frame{\frametitle{Example} 
	
\begin{itemize}
	\setlength\itemsep{1em}
	\item Suppose a woman plans to have 3 children. 
	\item Suppose at each birth, 
	$$P(\textrm{female child}) = 1/2$$ and the sex of the child at each birth is
	independent of the sex at any previous birth. 
	\item What is the probability of having all daughters?
\end{itemize} 

}

\frame{\frametitle{The binomial distribution}
	
	\vspace*{-0.5in}
	
	\begin{figure}
		\begin{center}
			\includegraphics[scale=0.4,angle=270]{binomial.pdf}
		\end{center}
	\end{figure}
}



\frame{\frametitle{The binomial distribution} 
	
	Let $Y$ be the number of daughters a woman will have, $n$ the number of children
	she will have, and $p$ the probability of a daughter at any birth. Then: \\ \ \\
	\[ P(Y=k) =
	\frac{n!}{(n-k)!k!}p^k(1-p)^{(n-k)}\] \ \\ \ \\ where $n! =
	1\times2\times3\times ... \times (n-1)\times n$, and $0!=1$. \\ \ \\

	
	}

\begin{frame}[fragile]{Calculating binomial probabilities in R}
$P(Y=3) = \frac{3!}{0!3!}0.5^3(1-0.5)^{0}$ \\ \ \\
which can be solved in R using:
<<echo=TRUE, eval=TRUE>>=
stats::dbinom(x = 3, size = 3, prob = 0.5)
@
\end{frame}

\begin{frame}[fragile]{The probability mass function (pmf)}

<<echo=TRUE, eval=TRUE>>=
plot(0:3/3, dbinom(x = 0:3, size = 3, prob = 0.5), type = "h")
@
\end{frame}

\begin{frame}[fragile]{What do we use it for?}
\small
\begin{itemize}
	\setlength\itemsep{0.7em}
	\item to make inferences about $\pi$ from  observed  proportion $p= y/n.$ \pause 
	\item to make inferences in more complex situations, e.g. 
	\begin{itemize}
			\setlength\itemsep{0.4em}
		\item Prevalence Difference: $\pi _{1} - \pi _{0}$
		\item Risk Difference (RD): $\pi _{1} - \pi _{0}$
		\item Risk Ratio, or its synonym Relative Risk (RR): $\pi _{1}\:/\:\pi _{0}$
		\item Odds Ratio (OR): $[\: \pi _{1}/(1-\pi _{1})\:] \: / \: [\: \pi _{0}\: / \: (1-\pi _{0}) \: ]$
		\item Trend in several $\pi $'s
	\end{itemize}
\end{itemize}
\end{frame}


\frame{\frametitle{Requirements for $y$ to have a Binomial (n, $\pi $) distribution} 
	\begin{enumerate}
\item Fixed sample size $n.$ 
\item Elements selected at random (i.e. same probability of being sampled) and independent of each other;
\item Each element in ``population'' is 0 or 1, but we are only interested in estimating proportion  ($\pi $) of 1's;  we are not interested in individuals. 
\item Denote by $y_{i}$ the value of the $i$-th sampled element.  P($y_{i}=1)$ is constant (it is $\pi$) across $i$.
\end{enumerate} }

\begin{comment}
\begin{frame}
\begin{figure}
	\begin{center}
		\includegraphics[scale=0.55]{BinomialTree2018.pdf}
		\caption{\scriptsize From 5 (independent and identically distributed) Bernoulli observations to Binomial $(n=5), \: \pi \textrm{ unspecified}$.}
			%There are $2^n$ possible (distinct) sequences of 0's and 1's, each with its probability. We are not interested in these $2^n$ probabilities, but in the probability that the sample  contains $y$ 1's and $(n-y)$ 0's. There are only ($n$+1) possibilities for $y$, namely 0 to $n.$ Fortunately, each of the $nC_y$ sequences that lead to the same sum or count ($y$), has the same probability. So we group the 2$^n$ sequences into $(n+1)$ sets, according to the sum or count. Each sequence in the set with  $y$ 1's and $(n-y)$ 0's has the same probability, namely $\pi ^{y}(1-\pi )^{n-y}$. Thus, in lieu of adding all such probabilities, we simply multiply this  probability by the number, $^{n}C _{y}$ -- shown in black -- of unique sequences in the set. Check: the numbers in black add to 2$^n.$ Nowadays, the $(n+1)$ probabilities are easily obtained by supplying a value for the \texttt{prob} argument in the \texttt{R} function \texttt{dbinom}, instead of  computing the binomial coefficient $nC_y$ by hand.}
	\end{center}
\end{figure}
\end{frame}
\end{comment}


\begin{frame}[fragile]{}
<<fig.asp = 0.858, echo = FALSE, eval = TRUE>>=
source("MakeBinomial3.R")
@
\end{frame}


\begin{frame}{Does the Binomial Distribution Apply if... ?}

\small
\begin{tabular}{lrl}
	\hline
	Interested in & $\pi$      &  the proportion of 16 year old girls  \\
	&              &   in Qu\'{e}bec protected against rubella \\
	& & \\
	Choose        & $n=100$ & girls: 20 at random from each of 5 randomly \\
	&                &selected schools [`cluster' sample] \\
	& & \\
	Count & $y$ & how many of the $n=100$  are protected \\
	& & \\
	
	\multicolumn{3}{l}{$\bullet$ Is $y \sim \textrm{Binomial}(n = 100, \pi $)? } \\
	\hline
	& & \\
	``SMAC'' & $\pi$      &   P(abnormal$\:|\:$Healthy) =0.03 for each chemistry \\
	& &                       in Auto-analyzer with $n=18$ channels  \\
	&         &  \\
	Count            & y$ $&  How many of $n=18$  give abnormal result.  \\
	& & \\
	\multicolumn{3}{l}{$\bullet$ Is $y \sim \textrm{Binomial}(n = 18, \pi =0.03$)? (cf. Ingelfinger: Clin. Biostatistics) } 
\end{tabular}
\end{frame}


\begin{frame}{Does the Binomial Distribution Apply if... ?}

\small
\begin{tabular}{lrl}
	\hline
	
	Interested in & $\pi _{u}$      &   proportion in `usual' exercise classes and in  \\
	& $\pi _{e}$      &   expt'l. exercise classes who `stay the course'  \\
	& & \\
	Randomly & 4   & classes of\\ 
	Allocate    &  \underline{25} & students each to usual course \\
	& $n_{u} = 100$ &  \\
	& 4  & classes of\\
	&  \underline{25} & students each to experimental course \\
	& $n_{e} =100$ &  \\
	
	Count & $y_u$ & how many of the $n_{u}=100$ complete course \\
	& $y_e$ & how many of the $n_{e}=100$  complete course \\
	
	\multicolumn{3}{l}{$\bullet$ Is $y_{u} \sim \textrm{Binomial}(n_{u} = 100,  \pi _{u}$) ?
		\ \  Is $y_{e} \sim \textrm{Binomial}(n_{e} = 100,  \pi _{e}$) ?} \\
	& & \\
	\hline
\end{tabular}
\end{frame}



\begin{frame}{Does the Binomial Distribution Apply if... ?}

\small
\begin{tabular}{lrl}
	\hline
	Sex Ratio & $n=4$& children in each family  \\
	& $y$ & number of girls in family \\
	& & \\
	\multicolumn{3}{l}{$\bullet$ Is variation of y across families Binomial (n = 4, $\pi $ = 0.49)?} \\
	\hline
	Pilot  &   &To estimate proportion $\pi$ of population that\\ 
	Study&   &  is eligible \& willing to participate in long-term\\
	&   & research study, keep recruiting until obtain   \\
	& $y=5$ &  who are. Have to approach $n$ to get $y$. \\
	& & \\
	\multicolumn{3}{l}{$\bullet$ Can we treat $y \sim \textrm{Binomial}(n, \pi$)?} \\
	\hline
\end{tabular}
\end{frame}


\begin{frame}{Calculating Binomial probabilities - Exactly}



\begin{itemize}
	\item  probability mass function (pmf): $P(Y=k) =
	\frac{n!}{(n-k)!k!}p^k(1-p)^{(n-k)}$
	\item in \texttt{R}: \texttt{dbinom(), pbinom(), qbinom()}: \newline probability mass, distribution/cdf, and quantile functions.
\end{itemize}

\end{frame}




\begin{frame}{Calculating Binomial probabilities - Using an approximation}

\small
\begin{itemize}
	\item Poisson Distribution ($n$ large;  small $\pi$)
	\item Normal (Gaussian) Distribution ($n$ large or midrange $\pi $) \footnote{\footnotesize
		For when you don't have access to software or Tables, e.g, on a plane} 
	\begin{itemize}
		\item Have to specify \textit{scale}. Say $n=10$, whether summary is a 
		\begin{tabular}{rllcc}
			&  \textbf{r.v. }        &  \textbf{e.g.} & \textbf{E} & \textbf{SD} \\ 
			\hline
			count:          &  $y$        &  2 & $n \times \pi$ & $\{n \times \pi \times (1-\pi) \}^{1/2}$ \\
			& & & & \\
			& & & & $n^{1/2} \times \sigma_{Bernoulli}$ \\
			
			& & & & \\
			proportion:   & $p=y/n$  & 0.2 & $ \pi$ & $\{\pi \times (1-\pi) / n \}^{1/2}$ \\
			& & & & \\
			
			& & & &  $\sigma_{Bernoulli} / n^{1/2}$\\
			
			& & & & \\
			percentage: &$100p\%$ & 20\% & $100 \times \pi$ & $100 \times SD[p]$ \\
			\hline
		\end{tabular}
		\item same core calculation for all 3 [only the \textit{scale} changes]. JH prefers (0,1), the same scale as $\pi.$
		
	\end{itemize}
	
\end{itemize}

\end{frame}



\begin{frame}[fragile]{Normal approximation to binomial is the CLT in action}
<<>>=
par(mfrow=c(2,2))
hist(rbinom(1000, 5, 0.3)/5)
hist(rbinom(1000, 10, 0.3)/10)
hist(rbinom(1000, 20, 0.3)/20)
hist(rbinom(1000, 100, 0.3)/100)
@
\end{frame}


\begin{frame}[fragile]{Normal approximation to binomial is the CLT in action}
<<>>=
par(mfrow=c(2,2))
hist(rbinom(1000, 5, 0.3))
hist(rbinom(1000, 10, 0.3))
hist(rbinom(1000, 20, 0.3))
hist(rbinom(1000, 100, 0.3))
@
\end{frame}

\begin{frame}{Example 1 from AAO Unit 21}
A drug manufacturer claims that its flu vaccine is 85\% effective; in other words, each person who is vaccinated stands an 85\% chance of developing immunity. Suppose that 200 randomly selected people are vaccinated. Let $Y$ be the number that develops immunity.

\begin{enumerate}
	\item What is the distribution of $Y$?
\item What is the mean and standard deviation for $Y$?
\item What is the probability that between 165 and 180 of the 200 people who were vaccinated
develop immunity? (Hint: Use a normal distribution to approximate the distribution of $Y$)
\end{enumerate}
\end{frame}


\begin{frame}[fragile]{Example 1 from AAO Unit 21 - Exact Method}

<<echo = TRUE, eval = TRUE, fig.asp = 0.618>>=
mosaic::xpbinom(q = c(165, 180), size = 200, prob = 0.85)
@
\end{frame}

\begin{frame}[fragile]{Example from AAO Unit 21- Normal Approximation}

<<echo = TRUE, eval = TRUE, fig.asp = 0.618>>=
mosaic::xpnorm(q = c(165,180), mean = 200 * 0.85, 
	sd = sqrt(200*0.85*0.15))
@
\end{frame}



\begin{frame}{Example 2 from AAO Unit 21}
People with O- blood are called universal donors because most people can receive an O-blood transfusion. The probability of having blood type O- is 0.066. Suppose a random sample of five people show up during a blood drive to donate blood. Let $Y$ be the number of people with blood type O-.

\begin{enumerate}
	\item What is the probability that none of the five people has blood type O-?
	\item What is the probability that exactly one of the five has blood type O-?
	\item What is the probability that no more than one of the five people has blood type O-?
	\item What is the probability that at least one of the five has blood type O-?
\end{enumerate}
\end{frame}


\begin{frame}[fragile]{1. What is the probability that none of the five people has blood type O-?}

$$ 
P(Y = 0) = \binom{5}{0} 0.066^0 (1- 0.066)^5
$$


<<echo = TRUE, eval = TRUE>>=
stats::dbinom(x = 0, size = 5, prob = 0.066)
(1-0.066)^5
@

\end{frame}



\begin{frame}[fragile]{2. What is the probability that exactly one of the five has blood type O-?}

$$ 
P(Y = 1) = \binom{5}{1} 0.066^1 (1- 0.066)^4
$$


<<echo = TRUE, eval = TRUE>>=
stats::dbinom(x = 1, size = 5, prob = 0.066)
@

\end{frame}



\begin{frame}[fragile]{3. What is the probability that no more than one of the five people has blood type O-?}
\footnotesize
\begin{align*}
P(Y \leq 1) & = P(Y = 0) + P(Y = 1) \\
& = \binom{5}{0} 0.066^0 (1- 0.066)^5 + \binom{5}{1} 0.066^1 (1- 0.066)^4
\end{align*}


<<echo = TRUE, eval = TRUE, fig.asp = 0.218>>=
stats::dbinom(x = 0, size = 5, prob = 0.066) + 
	stats::dbinom(x = 1, size = 5, prob = 0.066)
stats::pbinom(q = 1, size = 5, prob = 0.066)
mosaic::xpbinom(q = 1, size = 5, prob = 0.066)
@

\end{frame}




\begin{frame}[fragile]{4. What is the probability that more than one of the five has blood type O-?}
\footnotesize
\begin{align*}
P(Y > 1) & = P(Y = 2) + P(Y = 3) + P(Y=4) + P(Y=5) \\
& = 1 - P(Y \leq 1)
\end{align*}


<<echo = TRUE, eval = TRUE, fig.asp = 0.318>>=
1 - stats::pbinom(q = 1, size = 5, prob = 0.066)
mosaic::xpbinom(q = 1, size = 5, prob = 0.066, lower.tail = FALSE)
@

\end{frame}



\section{Inference concerning a proportion $\pi$, based on s.r.s. of size $n$}



\begin{frame}{Examples}
\small 
The \textbf{Parameter} $\pi$ of interest: the proportion ...
\begin{itemize}
	\item with undiagnosed hypertension / seeing MD during a 1-year span 
	\item who would respond to a specific therapy 
	\item still breast-feeding at 6 months
	\item of pairs where response on treatment $>$  response on placebo
	\item of Earth's surface covered by water
	\item who \textit{would} enrol in a long-term study or answer a questionnaire
	\item of twin pairs where left-handed twin dies first
	\item able to tell imported from domestic beer in a ``triangle taste test''
\end{itemize}

Inference via \textbf{Statistic}: the number ($y$) or proportion $p = y/n$ `positive' in an s.r.s. of size $n$.

\end{frame}



\begin{frame}{Frequentist vs. Bayesian Inference}
\small 
\Wider[5em]{
\begin{tabular}{ll}
	\textbf{Frequentist ($\S 2.1$}) & \textbf{Bayesian  ($\S 2.2$)} \\
	& \\
	- based on prob[ data $| \theta$ ], i.e. & - based on prob[ $\theta | $data ], i.e.,  \\
	- probability statements about data & - probability statements about $\pi $  \\
	& \\
	Evidence (P-value) against $H_{0}$: $\pi = \pi_{0}$ & - point estimate: \\
	& mean/median/mode of  \\
	Test of H$_{0}$: Is P-value $<$ (preset) $\alpha$? & posterior distribution of $\pi$ \\
	CI:  interval estmate & - (credible) interval  \\ 
\end{tabular}
}
\end{frame}




\begin{frame}
\Wider[5em]{

\includegraphics[width=4.95in,height=3.7in]{BinomialsVarious.pdf}

	
}
\end{frame}



\begin{frame}{Justification for the $n \times \pi$ and $n \times (1-\pi)$ $\geq 10$ }
notes on the Figure from the previous slide:
\begin{itemize}
	\setlength\itemsep{1em}
	\item \textbf{Binomial distributions}, on (0,1) scale (rather than \texttt{0:n}). Bigger  expected numbers of { \color{blue}{`\textbf{positives}'} } \textbf{\underline{and}} { \color{red}{`\textbf{negatives}'}} imply less probability mass at the extreme(s) and thus help to approximate the (binomial) sampling distribution by a Gaussian distribution with mean $\pi$ and 
	$\sigma = \frac{ \{\pi(1-\pi)\}^{1/2}}{\sqrt{n}}.$
		\item The amount of space needed at each extreme in order to accommodate a Gaussian distribution that does not spill over beyond the (0,1) boundaries is just another way to explain the (`taught but not explained')  rule-of-thumb that the expected numbers, $n \times \pi$ and $n \times (1-\pi)$ should should exceed 10 (or 5, or 8, depending on the textbook, and the edition!)
\end{itemize}
\end{frame}


\section{Frequentist Confidence Interval for $\pi$, based on an observed proportion $p = y/n$ \texttt{stats::binom.test} and \texttt{mosaic::binom.test} in \texttt{R}}


\begin{frame}{Some background}
\small

\begin{itemize}
	\item \underline{It is sad} that even today, with more emphasis on CI's and less on p-values and tests, we have to go through the `\texttt{.test}' to get to the CI. It is also of note that the procedure mentions the model (binomial) rather than the target parameter, the proportion $\pi.$ \pause
	
	\item The base \texttt{stats::binom.test} function in \texttt{R} has just one method, the Clopper-Pearson one. The \texttt{mosaic::binom.test} one has it and four others, and these allow us to appreciate why different ones might be used in different circumstances. We will start with the most familiar of them, the so-called `Wald' CI, which, because of its `point estimate $\pm \textrm{Margin.Of.Error}$' form, is \textit{symmetric}. \pause 
	
	\item The \texttt{mosaic::binom.test} allows for a vector of individual 0's and 1's, rather than the tallies of 1's and 0's required for \texttt{stats::binom.test} \pause 
	
	\item In practice, \textbf{CIs for proportions, and functions thereof, will come from regression models}. 
	
\end{itemize}
\end{frame}


\begin{frame}{CI based on Gaussian approximation to sampling distribution of the sample proportion $p$ -- the `Wald' method in \texttt{mosaic::binom.test}}
\small
\begin{itemize}
	\item The Wald CI has been taught as having the form: $$p \pm z^\star \times \textrm{SE}[p]$$ \pause
\item If the population sampled from has an (unknown) proportion $\pi$ of 1's
and an (unknown) proportion $1-\pi$ of 0's, then the \underline{theoretical} SD of all of the 1's and 0's sampled from is $\sigma_{0/1} = \sqrt{\pi(1-\pi)}$. \pause
\item Since we don't know the true value of $\sigma_{0/1} = \sqrt{\pi(1-\pi)}$, we replace it with a version where we \underline{substitute} $p$ for $\pi$, i.e. the estimated SD of all of the 1's and 0's sampled from is $\widehat{\sigma_{0/1}} = \sqrt{p(1-p)}$.

\end{itemize}

\end{frame}



\begin{frame}{CI based on Normal approximation to sampling distribution of the sample proportion $p$ -- the `Wald' method in \texttt{mosaic::binom.test}}
\small
\begin{itemize}
	\item Dividing this $\widehat{\sigma_{0/1}}$ by the square root of $n$, we get the standard error, our best estimate of the spread of the sampling distribution of a sample proportion, i.e.,
	$$SE[p] = \frac{\sqrt{p(1-p)}}{\sqrt{n}} \ \ \ \  \ = \ \frac{\widehat{\sigma_{0/1}}}{\sqrt{n}} \  .$$ \pause
	\item So, as it is \underline{traditionally} presented,  the CI becomes
	$$p \  \pm  \ z^\star \times \sqrt{\frac{p(1-p)}{n}}.$$ \pause 
	\item As we will see below, now that we seldom calculate a CI `from scratch,'  \underline{today} the Wald CI is better presented in the \underline{\texttt{R-computational} form}
	\scriptsize{$$\texttt{qnorm(p=c(0.025,0.975),  mean= p,  sd = sqrt(p*(1-p))/sqrt(n))}.$$}
\end{itemize}
\end{frame}

\begin{frame}{Sampling distribution of $p$}

\begin{center}
	\begin{figure}
\includegraphics[scale=0.3,angle=90]{prop1.pdf}
	\end{figure}
\end{center}

\end{frame}


\begin{frame}[fragile]{Example 1: Assessing the prevalence of HPV infections}
\small
NHANES found that 515 of a sample of 1921 women aged 14 to 59 years currently tested positive for HPV. Provide a 99\% confidence interval for HPV prevalence. 

<<echo = TRUE, eval = TRUE, fig.asp = 0.308>>=
n <- 1921
number_infected <- 515
p <- number_infected / n
s <- sqrt(p * (1 - p))
SEP <- s / sqrt(n)
mosaic::xqnorm(p=c(0.005,0.995), mean = p, sd = SEP)
@

\end{frame}


\begin{frame}[fragile]{Example 2: Assessing the prevalence of HPV infections}

<<echo = TRUE, eval = TRUE, fig.asp = 0.308, size = "tiny">>=
mosaic::binom.test(x = 515, n = 1921, ci.method=c("wald"), conf.level=0.99)
@
Note: HPV positive $\ne$ `success' !!
\end{frame}



\begin{frame}[fragile]{Example 2: Proportion of Earth Covered by Water}

Suppose our observed proportion of `water' locations was $p = 4/5,$ or 80\%.

<<echo = TRUE, eval = TRUE, fig.asp = 0.308, size = "tiny">>=
mosaic::binom.test(x = 4, n = 5, ci.method=c("wald"), conf.level=0.95)
@

\pause 

Clearly  the proportion or percentage of the Earth's surface covered by water cannot
be \underline{1.15} or \underline{115}\%.  

\end{frame}


\begin{frame}[fragile]{Example 2: Proportion of Earth Covered by Water}

<<echo = TRUE, eval = TRUE, fig.asp = 0.308>>=
stats::qnorm(p=c(0.025,0.975), mean = 0, sd = sqrt(0 * 1 / 5))
stats::qnorm(p=c(0.025,0.975), mean = 0.2, sd = sqrt(0.2 * 0.8 / 5))
stats::qnorm(p=c(0.025,0.975), mean = 0.4, sd = sqrt(0.4 * 0.6 / 5))
stats::qnorm(p=c(0.025,0.975), mean = 0.6, sd = sqrt(0.6 * 0.4 / 5))
stats::qnorm(p=c(0.025,0.975), mean = 0.8, sd = sqrt(0.8 * 0.2 / 5))
stats::qnorm(p=c(0.025,0.975), mean = 1, sd = sqrt(1 * 0 / 5))
@


\end{frame}



\begin{frame}{Example 2: Proportion of Earth Covered by Water}
Thus, \textbf{\underline{whatever your result}}, the Wald 95\% CI gives a \textit{\textbf{nonsensical}} result. Using the Normal/Gaussian approximation to the Binomial sampling distribution does not work when $n=5.$
\end{frame}


\section{What to do if a symmetric Gaussian-based CI doesn't make sense?}


\begin{frame}{What to do if a symmetric Gaussian-based CI doesn't make sense?}
\begin{itemize}
	\setlength\itemsep{1em}
\item \textbf{Answer}: use a non-symmetric one, and one that respects the (0,1) scale. \pause 
\item The other 4 methods in \texttt{mosaic::binom.test} do respect the (0,1) scale \pause 
\item We can also switch to the ($-\infty, \infty$)  \textit{logit} scale, computing the CI in this scale, and then back-transforming to the (0,1) scale $\to$ logistic regression.
\end{itemize}
\end{frame}



\begin{frame}{1. Asymmetric (Wilson and Clopper-Pearson) Methods}
content...
\end{frame}

\begin{frame}[fragile]{}
<<fig.asp = 0.858, echo = FALSE, eval = TRUE>>=
source("wilsonCI.R")
@
\end{frame}

\end{document}











