[
["index.html", "MATH 697 Syllabus General Information Course Description Grade Distribution Target Syllabus", " MATH 697 Sahir Rai Bhatnagar 2017-09-05 Syllabus General Information Instructor: Sahir Bhatnagar Email: sahir.bhatnagar@mail.mcgill.ca Website: http://sahirbhatnagar.com/MATH697/ Lectures: Tuesdays 9am - 12pm Office: TBD Office Hours: By appointment only Prerequisite(s): Calculus and Algebra Texts: Modern Mathematical Statistics with Applications, 2nd Edition by Jay L. Devore and Kenneth N. Berk Course Description The main learning outcomes of this course are to get a broad idea about some frequently used probability models and to learn basic results and techniques in probability theory and statistical inference. Most of the materials for the course will be drawn from the first seven chapters of the textbook. The book does not, however, contain all the materials we intend to cover in this course. Some extra notes will therefore be given on those topics not in the text book. We will also introduce computational methods in statistics with the statistical software program R. Grade Distribution Assignments 10% Quizzes 40% Final Exam 50% Target Syllabus Overview and Descriptive Statistics (Weeks 1-4) 1.1 Populations and Samples 1.2 Pictorial and Tabular Methods in Descriptive Statistics 1.3 Measures of Location 1.4 Measures of Variability Probability (Weeks 1-4) 2.1 Sample Spaces and Events 2.2 Axioms, Interpretations, and Properties of Probability 2.3 Counting Techniques 2.4 Conditional Probability 2.5 Independence Discrete Random Variables and Probability Distributions (Weeks 1-4) 3.1 Random Variables 3.2 Probability Distributions for Discrete Random Variables 3.3 Expected Values of Discrete Random Variables 3.4 Moments and Moment Generating Functions 3.5 The Binomial Probability Distribution 3.7 The Poisson Probability Distribution Continuous Random Variables and Probability Distributions (Weeks 5-8) 4.1 Probability Density Functions and Cumulative Distribution Functions 4.2 Expected Values and Moment Generating Functions 4.3 The Normal Distribution 4.7 Transformations of a Random Variable Joint Probability Distributions (Weeks 5-8) 5.1 Jointly Distributed Random Variables 5.2 Expected Values, Covariance, and Correlation 5.3 Conditional Distributions 5.4 Transformations of Random Variables Statistics and Sampling Distributions (Weeks 5-8) 6.1 Statistics and Their Distributions 6.2 The Distribution of the Sample Mean 6.3 The Mean, Variance, and MGF for Several Variables 6.4 Distributions Based on a Normal Random Sample Point Estimation (Weeks 9-12) 7.1 General Concepts and Criteria 7.2 Methods of Point Estimation Statistical Intervals Based on a Single Sample (Weeks 9-12) 8.1 Basic Properties of Confidence Intervals 8.2 Large-Sample Confidence Intervals for a Population Mean and Proportion 8.3 Intervals Based on a Normal Population Distribution 8.4 Confidence Intervals for the Variance and Standard Deviation of a Normal Population 8.5 Bootstrap Confidence Intervals Tests of Hypotheses Based on a Single Sample (Weeks 9-12) 9.1 Hypotheses and Test Procedures 9.2 Tests About a Population Mean 9.3 Tests Concerning a Population Proportion 9.4 P-Values 9.5 Some Comments on Selecting a Test Procedure "],
["prerequisites.html", "Prerequisites Install R and RStudio R Packages Introduction to R Background Reading", " Prerequisites Install R and RStudio All examples in this book are run in an R environment. You also need a recent version of RStudio, which is a software application that facilitates how you interact with R. It is developed by data enthusiasts who consider statistics to be more than just simulations, formulas and proofs. RStudio emphasizes the following: Version control: Why I should use version control especially for the solo data analyst. Reproducible research: seamless integration with RMarkdown for creating dynamic documents and presentations Creating R Packages: seamless integration with the devtools package for creating software that implements your statistical method or analysis. R Packages The following packages will be called upon at some point, so please install them before getting started with the tutorials. Enter the following command in R: install.packages(c(&quot;pacman&quot;, &quot;knitr&quot;, &quot;data.table&quot;, &quot;rmarkdown&quot;, &quot;tidyverse&quot;, &quot;boot&quot;, &quot;Hmisc&quot;)) Introduction to R Try out the interactive tutorial: http://swirlstats.com/ Background Reading The greatest thing about R is that there are so many people out there willing to help you. R users are constantly writing tutorials and creating packages to make your analysis tasks easier. Here is a very targeted list that I suggest reading prior to starting the tutorials Writing Functions for loops apply vs. for "],
["intro.html", "Chapter 1 Overview and Descriptive Statistics1 1.1 Populations and Samples 1.2 Pictorial and Tabular Methods in Descriptive Statistics 1.3 Measures of Location 1.4 Measures of Variability", " Chapter 1 Overview and Descriptive Statistics1 Statistical concepts and methods are not only useful but indeed often indispensable in understanding the world around us. They provide ways of gaining new insights into the behavior of many phenomena that you will encounter in your chosen field of specialization. The discipline of statistics teaches us how to make intelligent judgments and informed decisions in the presence of uncertainty and variation. Without uncertainty or variation, there would be little need for statistical methods or statisticians. If the yield of a crop were the same in every field, if all individuals reacted the same way to a drug, if everyone gave the same response to an opinion survey, and so on, then a single observation would reveal all desired information. 1.1 Populations and Samples We are constantly exposed to collections of facts, or data, both in our professional capacities and in everyday activities. The discipline of statistics provides methods for organizing and summarizing data and for drawing conclusions based on information contained in the data. An investigation will typically focus on a well-defined collection of objects constituting a population of interest: - In one study, the population might consist of all gelatin capsules of a particular type produced during a specified period. - Another investigation might involve the population consisting of all individuals who received a B.S. in mathematics during the most recent academic year. When desired information is available for all objects in the population, we have what is called a census. Constraints on time, money, and other scarce resources usually make a census impractical or infeasible. Instead, a subset of the population, a sample, is selected in some prescribed manner. Thus we might obtain a sample of pills from a particular production run as a basis for investigating whether pills are conforming to manufacturing specifications, or we might select a sample of last year’s graduates to obtain feedback about the quality of the curriculum. 1.1.1 Variable We are usually interested only in certain characteristics of the objects in a population: the amount of vitamin C in the pill, the gender of a mathematics graduate, the age at which the individual graduated, and so on. A variable is any characteristic whose value may change from one object to another in the population. Can be categorical (male/female) or numerical (temperature). data type description univariate consists of observations on a single variable bivariate observations are made on each of two variables multivariate more than two variables 1.1.2 Branches of Statistics Descriptive Statistics: summarize and describe important features of the data. Can be graphs (histograms, boxplots, and scatter plots), or numeric summaries (mean, standard deviations, and correlation coefficients) Inferential Statistics: Techniques for generalizing from a sample to a population. Having obtained a sample from a population, an investigator would frequently like to use sample information to draw some type of conclusion (make an inference of some sort) about the population. That is, the sample is a means to an end rather than an end in itself. The focus of this couse is Inferential statistics. But to get there we need to understand the basic concepts of probability The relationship between the two disciplines can be summarized by saying that probability reasons from the population to the sample (deductive reasoning), whereas inferential statistics reasons from the sample to the population (inductive reasoning). Before we can understand what a particular sample can tell us about the population, we should first understand the uncertainty associated with taking a sample from a given population. This is why we study probability before statistics. Example 1.1 (Use of manual lap belts in cars equipped with automatic shoulder belt systems) Probability: assume that 50% of all drivers in a certain metropolitan area regularly use their lap belt \\(\\rightarrow\\) an assumption about the population. We might ask - How likely is it that a sample of 100 such drivers will include at least 70 who regularly use their lap belt? - How many of the drivers in a sample of size 100 can we expect to regularly use their lap belt? Inference: a sample of 100 drivers of such cars revealed that 65 regularly use their lap belt. We might ask - Does this provide substantial evidence for concluding that more than 50% of all such drivers in this area regularly use their lap belt We are attempting to use sample information to answer a question about the structure of the entire population from which the sample was selected. 1.2 Pictorial and Tabular Methods in Descriptive Statistics 1.3 Measures of Location 1.4 Measures of Variability Devore and Berk.↩ "],
["probability.html", "Chapter 2 Probability 2.1 Introduction2", " Chapter 2 Probability 2.1 Introduction2 The random variation associated with measurement procedures in a scientific analysis requires a framework in which the uncertainty and variability that are inherent in the procedure can be handled. The key goal of Probability and Statistical modelling is to establish a mathematical framework within which random variation (due, for example, to experimental error or natural variation) can be quantified so that systematic variation (arising due to potentially important biological differences) can be studied. Broadly, the involves several different stages: \\[\\begin{equation*} \\begin{array}{cl} \\text{{THEORETICAL MODELLING}} &amp; \\rightarrow \\text{{MATHEMATICAL/PROBABILISTIC MODELLING}} \\\\ \\downarrow &amp; \\\\ \\text{{PREDICTION}} &amp; \\\\ \\downarrow &amp; \\\\ \\text{{EXPERIMENTATION/OBSERVATION}} &amp; \\\\ \\downarrow &amp; \\\\ \\text{{VALIDATION}} &amp; \\end{array} \\end{equation*}\\] Mathematical/Probabilistic modelling facilitates PREDICTION; Statistical Analysis provides the means of validation of predicted behaviour. To explain the variation in observed data, we need to introduce the concept of a probability distribution. Essentially we need to be able to model, or specify, or compute the chance of observing the data that we collect or expect to collect. This will then allow us to assess how likely the data were to occur by chance alone, that is, how surprising the observed data are in light of an assumed theoretical model. For example, consider two nucleotide sequences of the same length that we wish to assess for similarity: Example 2.1 (Two nucleotide sequences) \\[\\begin{equation*} \\begin{array}{ll} \\text{{Sequence 1}}{\\qquad } &amp; ATAGTAGATACGCACCGAGGA \\\\ &amp; \\\\ \\text{{Sequence 2}}{\\qquad } &amp; ATCTTAGATAGGCACTGAGGA \\end{array} \\end{equation*}\\] How can we assess sequence similarity formally ? The number of discordant positions is 4, but how informative is that summary measure ? Perhaps we need to assess the chance, for example, that a point mutation \\[ A\\rightarrow C \\] occurs (as in the discordant position 3) in unit evolutionary time. Perhaps the chance of observing a sub-sequence \\[\\begin{equation*} ATCTTA \\end{equation*}\\] rather than \\[\\begin{equation*} ATAGTA \\end{equation*}\\] (in positions 1-6) is important. Is the hidden (or latent) structure in the sequence, corresponding to whether the sequence originates from a coding region or otherwise, important ? Can we even infer the hidden structure in light of the data we have observed ? These questions can only really be answered when we have an understanding of randomness and variation. The framework that we will use to pose and answer such questions formally is given to us by probability theory. 2.1.1 Probability: A Measure of Uncertainty3 Often in life we are confronted by our own ignorance. Whether we are pondering tonight’s traffic jam, tomorrow’s weather, next week’s stock prices, an upcoming election, or where we left our hat, often we do not know an outcome with certainty. Instead, we are forced to guess, to estimate, to hedge our bets. Probability is the science of uncertainty. It provides precise mathematical rules for understanding and analyzing our own ignorance. It does not tell us tomorrow’s weather or next week’s stock prices; rather, it gives us a framework for working with our limited knowledge and for making sensible decisions based on what we do and do not know. To say there is a 40% chance of rain tomorrow is not to know tomorrow’s weather. Rather, it is to know what we do not know about tomorrow’s weather. In this course, we will develop a more precise understanding of what it means to say there is a 40% chance of rain tomorrow. We will learn how to work with ideas of randomness, probability, expected value, prediction, estimation, etc., in ways that are sensible and mathematically clear. Reproduced with permission from http://www.math.mcgill.ca/dstephens/↩ http://www.utstat.toronto.edu/mikevans/jeffrosenthal/book.pdf↩ "]
]
