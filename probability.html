<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>EPIB 607</title>
  <meta name="description" content="Course material for EPIB 607 at McGill University">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="EPIB 607" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://sahirbhatnagar.com/EPIB607" />
  
  <meta property="og:description" content="Course material for EPIB 607 at McGill University" />
  <meta name="github-repo" content="sahirbhatnagar/EPIB607" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="EPIB 607" />
  
  <meta name="twitter:description" content="Course material for EPIB 607 at McGill University" />
  

<meta name="author" content="Sahir Bhatnagar and James Hanley">


<meta name="date" content="2018-08-23">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="intro.html">
<link rel="next" href="discrete-random-variables-and-probability-distributions.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">EPIB 607</a></li>

<li class="divider"></li>
<li class="part"><span><b>I Preface</b></span></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#development"><i class="fa fa-check"></i>Development</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#general-information"><i class="fa fa-check"></i>General Information</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#course-description"><i class="fa fa-check"></i>Course Description</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#grade-distribution"><i class="fa fa-check"></i>Grade Distribution</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#target-syllabus"><i class="fa fa-check"></i>Target Syllabus</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#overview-and-descriptive-statistics-weeks-1-4"><i class="fa fa-check"></i>Overview and Descriptive Statistics (Weeks 1-4)</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#probability-weeks-1-4"><i class="fa fa-check"></i>Probability (Weeks 1-4)</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#discrete-random-variables-and-probability-distributions-weeks-1-4"><i class="fa fa-check"></i>Discrete Random Variables and Probability Distributions (Weeks 1-4)</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#continuous-random-variables-and-probability-distributions-weeks-5-8"><i class="fa fa-check"></i>Continuous Random Variables and Probability Distributions (Weeks 5-8)</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#joint-probability-distributions-weeks-5-8"><i class="fa fa-check"></i>Joint Probability Distributions (Weeks 5-8)</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#sampling-distributions-and-limits-weeks-5-8"><i class="fa fa-check"></i>Sampling Distributions and Limits (Weeks 5-8)</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#statistical-inference-weeks-9-12"><i class="fa fa-check"></i>Statistical Inference (Weeks 9-12)</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#likelihood-inference-weeks-9-12"><i class="fa fa-check"></i>Likelihood Inference (Weeks 9-12)</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#regression-and-correlation-weeks-9-12"><i class="fa fa-check"></i>Regression and Correlation (Weeks 9-12)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="prerequisites.html"><a href="prerequisites.html"><i class="fa fa-check"></i>Prerequisites</a><ul>
<li class="chapter" data-level="" data-path="prerequisites.html"><a href="prerequisites.html#install-r-and-rstudio"><i class="fa fa-check"></i>Install R and RStudio</a></li>
<li class="chapter" data-level="" data-path="prerequisites.html"><a href="prerequisites.html#r-packages"><i class="fa fa-check"></i>R Packages</a></li>
<li class="chapter" data-level="" data-path="prerequisites.html"><a href="prerequisites.html#introduction-to-r"><i class="fa fa-check"></i>Introduction to R</a></li>
<li class="chapter" data-level="" data-path="prerequisites.html"><a href="prerequisites.html#background-reading"><i class="fa fa-check"></i>Background Reading</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="slides.html"><a href="slides.html"><i class="fa fa-check"></i>Slides</a></li>
<li class="chapter" data-level="" data-path="assignments.html"><a href="assignments.html"><i class="fa fa-check"></i>Assignments</a></li>
<li class="chapter" data-level="" data-path="quiz.html"><a href="quiz.html"><i class="fa fa-check"></i>Quiz</a></li>
<li class="chapter" data-level="" data-path="r-code.html"><a href="r-code.html"><i class="fa fa-check"></i>R Code</a><ul>
<li class="chapter" data-level="0.1" data-path="r-code.html"><a href="r-code.html#central-limit-theorem-in-action"><i class="fa fa-check"></i><b>0.1</b> Central Limit Theorem in Action</a></li>
<li class="chapter" data-level="0.2" data-path="r-code.html"><a href="r-code.html#impc-dataset"><i class="fa fa-check"></i><b>0.2</b> IMPC Dataset</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="distribution-tables.html"><a href="distribution-tables.html"><i class="fa fa-check"></i>Distribution Tables</a><ul>
<li class="chapter" data-level="0.3" data-path="distribution-tables.html"><a href="distribution-tables.html#standard-normal"><i class="fa fa-check"></i><b>0.3</b> Standard Normal</a></li>
<li class="chapter" data-level="0.4" data-path="distribution-tables.html"><a href="distribution-tables.html#t-distribution"><i class="fa fa-check"></i><b>0.4</b> t-Distribution</a></li>
</ul></li>
<li class="part"><span><b>II Part I</b></span></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Overview and Descriptive Statistics</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#populations-and-samples"><i class="fa fa-check"></i><b>1.1</b> Populations and Samples</a><ul>
<li class="chapter" data-level="1.1.1" data-path="intro.html"><a href="intro.html#variable"><i class="fa fa-check"></i><b>1.1.1</b> Variable</a></li>
<li class="chapter" data-level="1.1.2" data-path="intro.html"><a href="intro.html#branches-of-statistics"><i class="fa fa-check"></i><b>1.1.2</b> Branches of Statistics</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#pictorial-and-tabular-methods-in-descriptive-statistics"><i class="fa fa-check"></i><b>1.2</b> Pictorial and Tabular Methods in Descriptive Statistics</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#measures-of-location"><i class="fa fa-check"></i><b>1.3</b> Measures of Location</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#measures-of-variability"><i class="fa fa-check"></i><b>1.4</b> Measures of Variability</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>2</b> Probability</a><ul>
<li class="chapter" data-level="" data-path="probability.html"><a href="probability.html#introduction1"><i class="fa fa-check"></i>Introduction</a><ul>
<li class="chapter" data-level="" data-path="probability.html"><a href="probability.html#probability-a-measure-of-uncertainty2"><i class="fa fa-check"></i>Probability: A Measure of Uncertainty</a></li>
</ul></li>
<li class="chapter" data-level="2.1" data-path="probability.html"><a href="probability.html#sample-spaces-and-events"><i class="fa fa-check"></i><b>2.1</b> Sample Spaces and Events</a><ul>
<li class="chapter" data-level="2.1.1" data-path="probability.html"><a href="probability.html#sample-spaces"><i class="fa fa-check"></i><b>2.1.1</b> Sample Spaces</a></li>
<li class="chapter" data-level="2.1.2" data-path="probability.html"><a href="probability.html#events"><i class="fa fa-check"></i><b>2.1.2</b> Events</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="probability.html"><a href="probability.html#axioms-interpretations-and-properties-of-probability"><i class="fa fa-check"></i><b>2.2</b> Axioms, Interpretations, and Properties of Probability</a></li>
<li class="chapter" data-level="2.3" data-path="probability.html"><a href="probability.html#counting-techniques"><i class="fa fa-check"></i><b>2.3</b> Counting Techniques</a><ul>
<li class="chapter" data-level="2.3.1" data-path="probability.html"><a href="probability.html#permutations"><i class="fa fa-check"></i><b>2.3.1</b> Permutations</a></li>
<li class="chapter" data-level="2.3.2" data-path="probability.html"><a href="probability.html#combinations"><i class="fa fa-check"></i><b>2.3.2</b> Combinations</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="probability.html"><a href="probability.html#conditional-probability"><i class="fa fa-check"></i><b>2.4</b> Conditional Probability</a><ul>
<li class="chapter" data-level="2.4.1" data-path="probability.html"><a href="probability.html#law-of-total-probability"><i class="fa fa-check"></i><b>2.4.1</b> Law of Total Probability</a></li>
<li class="chapter" data-level="2.4.2" data-path="probability.html"><a href="probability.html#bayes-rule"><i class="fa fa-check"></i><b>2.4.2</b> Bayes’ Rule</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="probability.html"><a href="probability.html#independence"><i class="fa fa-check"></i><b>2.5</b> Independence</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="discrete-random-variables-and-probability-distributions.html"><a href="discrete-random-variables-and-probability-distributions.html"><i class="fa fa-check"></i><b>3</b> Discrete Random Variables and Probability Distributions</a><ul>
<li class="chapter" data-level="" data-path="discrete-random-variables-and-probability-distributions.html"><a href="discrete-random-variables-and-probability-distributions.html#introduction"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="3.1" data-path="discrete-random-variables-and-probability-distributions.html"><a href="discrete-random-variables-and-probability-distributions.html#random-variables"><i class="fa fa-check"></i><b>3.1</b> Random Variables</a></li>
<li class="chapter" data-level="3.2" data-path="discrete-random-variables-and-probability-distributions.html"><a href="discrete-random-variables-and-probability-distributions.html#probability-distributions-for-discrete-random-variables"><i class="fa fa-check"></i><b>3.2</b> Probability Distributions for Discrete Random Variables</a></li>
<li class="chapter" data-level="3.3" data-path="discrete-random-variables-and-probability-distributions.html"><a href="discrete-random-variables-and-probability-distributions.html#expected-values-of-discrete-random-variables"><i class="fa fa-check"></i><b>3.3</b> Expected Values of Discrete Random Variables</a></li>
<li class="chapter" data-level="3.4" data-path="discrete-random-variables-and-probability-distributions.html"><a href="discrete-random-variables-and-probability-distributions.html#moments-and-moment-generating-functions"><i class="fa fa-check"></i><b>3.4</b> Moments and Moment Generating Functions</a></li>
<li class="chapter" data-level="3.5" data-path="discrete-random-variables-and-probability-distributions.html"><a href="discrete-random-variables-and-probability-distributions.html#the-binomial-probability-distribution"><i class="fa fa-check"></i><b>3.5</b> The Binomial Probability Distribution</a></li>
<li class="chapter" data-level="3.6" data-path="discrete-random-variables-and-probability-distributions.html"><a href="discrete-random-variables-and-probability-distributions.html#the-poisson-probability-distribution"><i class="fa fa-check"></i><b>3.6</b> The Poisson Probability Distribution</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="continuous-variables-and-probability-distributions.html"><a href="continuous-variables-and-probability-distributions.html"><i class="fa fa-check"></i><b>4</b> Continuous Variables and Probability Distributions</a><ul>
<li class="chapter" data-level="" data-path="continuous-variables-and-probability-distributions.html"><a href="continuous-variables-and-probability-distributions.html#introduction-1"><i class="fa fa-check"></i>Introduction</a></li>
</ul></li>
<li class="appendix"><span><b>R Tutorial</b></span></li>
<li class="chapter" data-level="A" data-path="vectorization-apply-and-for-loops.html"><a href="vectorization-apply-and-for-loops.html"><i class="fa fa-check"></i><b>A</b> Vectorization, *apply and for loops</a><ul>
<li class="chapter" data-level="A.1" data-path="vectorization-apply-and-for-loops.html"><a href="vectorization-apply-and-for-loops.html#vectorization"><i class="fa fa-check"></i><b>A.1</b> Vectorization</a></li>
<li class="chapter" data-level="A.2" data-path="vectorization-apply-and-for-loops.html"><a href="vectorization-apply-and-for-loops.html#family-of-apply-functions"><i class="fa fa-check"></i><b>A.2</b> Family of <code>*apply</code> functions</a><ul>
<li class="chapter" data-level="A.2.1" data-path="vectorization-apply-and-for-loops.html"><a href="vectorization-apply-and-for-loops.html#loops-vs.apply"><i class="fa fa-check"></i><b>A.2.1</b> Loops vs. Apply</a></li>
<li class="chapter" data-level="A.2.2" data-path="vectorization-apply-and-for-loops.html"><a href="vectorization-apply-and-for-loops.html#descriptive-statistics-using-apply"><i class="fa fa-check"></i><b>A.2.2</b> Descriptive Statistics using <code>*apply</code></a></li>
<li class="chapter" data-level="A.2.3" data-path="vectorization-apply-and-for-loops.html"><a href="vectorization-apply-and-for-loops.html#creating-new-columns-using-sapply"><i class="fa fa-check"></i><b>A.2.3</b> Creating new columns using <code>sapply</code></a></li>
<li class="chapter" data-level="A.2.4" data-path="vectorization-apply-and-for-loops.html"><a href="vectorization-apply-and-for-loops.html#applying-functions-to-subsets-using-tapply"><i class="fa fa-check"></i><b>A.2.4</b> Applying functions to subsets using <code>tapply</code></a></li>
<li class="chapter" data-level="A.2.5" data-path="vectorization-apply-and-for-loops.html"><a href="vectorization-apply-and-for-loops.html#nested-for-loops-using-mapply"><i class="fa fa-check"></i><b>A.2.5</b> Nested for loops using <code>mapply</code></a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="vectorization-apply-and-for-loops.html"><a href="vectorization-apply-and-for-loops.html#creating-dynamic-documents-with-mapply"><i class="fa fa-check"></i><b>A.3</b> Creating dynamic documents with <code>mapply</code></a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="appendix-b.html"><a href="appendix-b.html"><i class="fa fa-check"></i><b>B</b> Appendix B</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://sahirbhatnagar.com" target="blank">Built with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">EPIB 607</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="probability" class="section level1">
<h1><span class="header-section-number">Chapter 2</span> Probability</h1>
<div id="introduction1" class="section level2 unnumbered">
<h2>Introduction<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a></h2>
<p>The random variation associated with <em>measurement</em> procedures in a scientific analysis requires a framework in which the <strong>uncertainty</strong> and <strong>variability</strong> that are inherent in the procedure can be handled. The key goal of Probability and Statistical modelling is to establish a mathematical framework within which <em>random</em> variation (due, for example, to experimental error or natural variation) can be quantified so that <em>systematic</em> variation (arising due to potentially important biological differences) can be studied.</p>
<p>Broadly, the  involves several different stages:</p>
<span class="math display">\[\begin{equation*}
\begin{array}{cl}
\text{{THEORETICAL MODELLING}} &amp; \rightarrow \text{{MATHEMATICAL/PROBABILISTIC MODELLING}} \\
\downarrow &amp;  \\
\text{{PREDICTION}} &amp;  \\
\downarrow &amp;  \\
\text{{EXPERIMENTATION/OBSERVATION}} &amp;  \\
\downarrow &amp;  \\
\text{{VALIDATION}} &amp;
\end{array}
\end{equation*}\]</span>
<p><em>Mathematical/Probabilistic</em> <em>modelling</em> facilitates PREDICTION; <em>Statistical Analysis</em> provides the means of validation of predicted behaviour.</p>
<p>To explain the variation in observed data, we need to introduce the concept of a <em>probability distribution</em>. Essentially we need to be able to model, or specify, or compute the <em>chance</em> of observing the data that we collect or expect to collect. This will then allow us to assess how likely the data were to occur by chance alone, that is, how <em>surprising</em> the observed data are in light of an assumed theoretical model.</p>
<p>For example, consider two nucleotide sequences of the same length that we wish to assess for similarity:</p>

<div class="example">
<span id="exm:unnamed-chunk-10" class="example"><strong>Example 2.1  (Two nucleotide sequences)  </strong></span>
<span class="math display">\[\begin{equation*}
\begin{array}{ll}
\text{{Sequence 1}}{\qquad } &amp; ATAGTAGATACGCACCGAGGA \\
&amp;  \\
\text{{Sequence 2}}{\qquad } &amp; ATCTTAGATAGGCACTGAGGA
\end{array}
\end{equation*}\]</span>
How can we assess sequence similarity formally ? The number of discordant positions is 4, but how informative is that summary measure ? Perhaps we need to assess the chance, for example, that a point mutation <span class="math display">\[ A\rightarrow C \]</span> occurs (as in the discordant position 3) in unit evolutionary time. Perhaps the chance of observing a sub-sequence
<span class="math display">\[\begin{equation*}
ATCTTA
\end{equation*}\]</span>
rather than
<span class="math display">\[\begin{equation*}
ATAGTA
\end{equation*}\]</span>
<p>(in positions 1-6) is important.</p>
<ul>
<li>Is the hidden (or <em>latent</em>) structure in the sequence, corresponding to whether the sequence originates from a coding region or otherwise, important ?</li>
<li>Can we even infer the hidden structure in light of the data we have observed ?<br />
</li>
</ul>
</div>

<p>These questions can only really be answered when we have an understanding of randomness and variation. The framework that we will use to pose and answer such questions formally is given to us by <em>probability theory</em>.</p>
<div id="probability-a-measure-of-uncertainty2" class="section level3 unnumbered">
<h3>Probability: A Measure of Uncertainty<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a></h3>
<p>Often in life we are confronted by our own ignorance. Whether we are pondering tonight’s traffic jam, tomorrow’s weather, next week’s stock prices, an upcoming election, or where we left our hat, often we do not know an outcome with certainty. Instead, we are forced to guess, to estimate, to hedge our bets.</p>
<blockquote>
<p>Probability is the science of uncertainty.</p>
</blockquote>
<p>It provides precise mathematical rules for understanding and analyzing our own ignorance. It does not tell us tomorrow’s weather or next week’s stock prices; rather, it gives us a <strong>framework for working with our limited knowledge</strong> and for <strong>making sensible decisions based on what we do and do not know</strong>.</p>
<p>To say there is a 40% chance of rain tomorrow is not to know tomorrow’s weather. Rather, it is to <strong>know what we do not know</strong> about tomorrow’s weather. In this course, we will develop a more precise understanding of what it means to say there is a 40% chance of rain tomorrow. We will learn how to work with ideas of randomness, probability, expected value, prediction, estimation, etc., in ways that are sensible and mathematically clear.</p>
</div>
</div>
<div id="sample-spaces-and-events" class="section level2">
<h2><span class="header-section-number">2.1</span> Sample Spaces and Events</h2>
<div id="sample-spaces" class="section level3">
<h3><span class="header-section-number">2.1.1</span> Sample Spaces</h3>

<div class="definition">
<span id="def:unnamed-chunk-11" class="definition"><strong>Definition 2.1  (Sample Space)  </strong></span>The sample space <span class="math inline">\(\Omega\)</span> is the set of possible outcomes of an experiment. Points <span class="math inline">\(\omega\)</span> in <span class="math inline">\(\Omega\)</span> are called sample outcomes, realizations, or elements.
</div>


<div class="example">
<span id="exm:unnamed-chunk-12" class="example"><strong>Example 2.2  (Coin tossing)  </strong></span><span class="math inline">\(\Omega = \left\lbrace H, T \right\rbrace\)</span>
</div>


<div class="example">
<span id="exm:unnamed-chunk-13" class="example"><strong>Example 2.3  (Dice)  </strong></span><span class="math inline">\(\Omega = \left\lbrace 1,2,3,4,5,6 \right\rbrace\)</span>
</div>


<div class="example">
<span id="exm:unnamed-chunk-14" class="example"><strong>Example 2.4  (Proportions)  </strong></span><span class="math inline">\(\Omega = \left\lbrace x : 0 \leq x \leq 1 \right\rbrace\)</span>
</div>


<div class="example">
<span id="exm:unnamed-chunk-15" class="example"><strong>Example 2.5  (Time measurement)  </strong></span><span class="math inline">\(\Omega = \left\lbrace x : x &gt; 0 \right\rbrace = {\mathbb{R}}^{+}\)</span>
</div>


<div class="example">
<span id="exm:unnamed-chunk-16" class="example"><strong>Example 2.6  (Temperature measurement)  </strong></span><span class="math inline">\(\Omega = \left\{ x:a\leq x\leq b\right\} \subseteq { \mathbb{R}}\)</span>
</div>


<div class="example">
<span id="exm:unnamed-chunk-17" class="example"><strong>Example 2.7  (Biological Sequence Analysis)  </strong></span>The experiment may involve the observation of a nucleotide or protein sequence, so that the sample space <span class="math inline">\(\Omega\)</span> may comprise all sequences (of bases/amino acids) up to a given length, and a sample outcome would be a particular observed sequence.
</div>

<p>There are two basic types of experiment: - Counting - Measurement</p>
<p>We shall see that these two types lead to two distinct ways of specifying probability distributions.</p>
The collection of sample outcomes is a <strong>set</strong> (a collection of items) written as
<span class="math display">\[\begin{equation*}
s\in \Omega
\end{equation*}\]</span>
<p>if <span class="math inline">\(s\)</span> <em>is a member of the set</em> <span class="math inline">\(\Omega\)</span>.</p>
</div>
<div id="events" class="section level3">
<h3><span class="header-section-number">2.1.2</span> Events</h3>

<div class="definition">
<span id="def:unnamed-chunk-18" class="definition"><strong>Definition 2.2  (Event)  </strong></span>An event <span class="math inline">\(E\)</span> is a subset of the sample space <span class="math inline">\(\Omega\)</span> (<span class="math inline">\(E \subseteq \Omega\)</span>). Events are usually denoted by upper case letters near the beginning of the alphabet, like <span class="math inline">\(A, B, C\)</span>. An event which consists of only one outcome is called a simple (or elementary event); otherwise it is a compound event.
</div>


<div class="rmdnote">
The sets <span class="math inline">\(\Omega\)</span> and <span class="math inline">\(E\)</span> can be either be written as a list of items, for example,
<span class="math display">\[\begin{equation*}
E=\left\{ s_{1},s_{2},...,s_{n},...\right\}
\end{equation*}\]</span>
which may a finite or infinite list, or can only be represented by a continuum of outcomes, for example
<span class="math display">\[\begin{equation*}
E=\left\{ x:0.6&lt;x\leq 2.3\right\}
\end{equation*}\]</span>
</div>

<p>Events are manipulated using <strong>set theory</strong> notation; if <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are two events, <span class="math inline">\(A, B \subseteq \Omega\)</span>, then</p>
<ul>
<li><span class="math inline">\(A \cup B\)</span> is the set of outcomes that belong to <span class="math inline">\(A\)</span> <strong>or</strong> to <span class="math inline">\(B\)</span>, or to both,</li>
<li><span class="math inline">\(A \cap B\)</span> is the set of outcomes that belong to both <span class="math inline">\(A\)</span> <strong>and</strong> to <span class="math inline">\(B\)</span>.</li>
<li><span class="math inline">\(A^c\)</span> (complement of <span class="math inline">\(A\)</span>) is the set of outcomes <strong>not</strong> in <span class="math inline">\(A\)</span></li>
<li><span class="math inline">\(A \backslash B = A \cap B^c\)</span></li>
</ul>
<p>The empty event will be denoted by <span class="math inline">\(\varnothing\)</span>. Two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are mutually exclusive if <span class="math inline">\(A \cap B = \varnothing\)</span>, i.e., the collection of sample outcomes have no element in common.</p>
<div class="figure">
<img src="images/venn.png" />

</div>
</div>
</div>
<div id="axioms-interpretations-and-properties-of-probability" class="section level2">
<h2><span class="header-section-number">2.2</span> Axioms, Interpretations, and Properties of Probability</h2>

<div class="definition">
<p><span id="def:unnamed-chunk-20" class="definition"><strong>Definition 2.3  (Axioms (basic properties) of Probability)  </strong></span>To ensure that the probability assignments will be consistent with our intuitive notions of probability, all assign- ments should satisfy the following axioms (basic properties) of probability</p>
<ul>
<li><strong>AXIOM 1:</strong> For any event <span class="math inline">\(A\)</span>, <span class="math display">\[ P(A) \geq 0 \]</span></li>
<li><strong>AXIOM 2:</strong> <span class="math display">\[ P(\Omega) = 1 \]</span></li>
<li><strong>AXIOM 3:</strong> If <span class="math inline">\(A_1, A_2, \ldots\)</span> is an infinite collection of disjoint events, then <span class="math display">\[   P\left(A_1 \cup A_2 \cup \cdots \right) = \sum_{i=1}^{\infty} P(A_i)  \]</span></li>
</ul>
</div>


<div class="proposition">
<span id="prp:unnamed-chunk-21" class="proposition"><strong>Proposition 2.1  </strong></span><span class="math inline">\(P(\varnothing) = 0\)</span> where <span class="math inline">\(\varnothing\)</span> is the null event. This in turn implies that the property contained in Axiom 3 is valid for a finite collection of events.
</div>


<div class="proposition">
<span id="prp:unnamed-chunk-22" class="proposition"><strong>Proposition 2.2  </strong></span>For any event <span class="math inline">\(A\)</span>,<br />
<span class="math display">\[ P(A) = 1 - P(A^c) \]</span>
</div>


<div class="proposition">
<span id="prp:unnamed-chunk-23" class="proposition"><strong>Proposition 2.3  </strong></span>For any event <span class="math inline">\(A\)</span>,<br />
<span class="math display">\[ P(A) \leq 1 \]</span>
</div>


<div class="proposition">
<span id="prp:unnamed-chunk-24" class="proposition"><strong>Proposition 2.4  </strong></span>For any events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>,<br />
<span class="math display">\[ P(A \cup B) = P(A) + P(B) - P(A \cap B) \]</span>
</div>

</div>
<div id="counting-techniques" class="section level2">
<h2><span class="header-section-number">2.3</span> Counting Techniques</h2>
<p>When the various outcomes of an experiment are equally likely (the same probability is assigned to each simple event), the task of computing probabilities reduces to counting. In particular, if <span class="math inline">\(N\)</span> is the number of outcomes in a sample space and <span class="math inline">\(N(A)\)</span> is the number of outcomes contained in an event <span class="math inline">\(A\)</span>, then <span class="math display">\[ P(A) = \frac{N(A)}{N} \]</span></p>

<div class="proposition">
<span id="prp:unnamed-chunk-25" class="proposition"><strong>Proposition 2.5  (Product rule for ordered pairs)  </strong></span>If the first element or object of an ordered pair can be selected in <span class="math inline">\(n_1\)</span> ways, and for each of these <span class="math inline">\(n_1\)</span> ways the second element of the pair can be selected in <span class="math inline">\(n_2\)</span> ways, then the number of pairs is <span class="math inline">\(n_1 \cdot n_2\)</span>.
</div>

<div id="permutations" class="section level3">
<h3><span class="header-section-number">2.3.1</span> Permutations</h3>

<div class="definition">
<p><span id="def:unnamed-chunk-26" class="definition"><strong>Definition 2.4  (Permutation)  </strong></span>Any ordered sequence of <span class="math inline">\(k\)</span> objects taken from a set of <span class="math inline">\(n\)</span> distinct objects is called a permutation of size <span class="math inline">\(k\)</span> of the objects. The number of permutations of size <span class="math inline">\(k\)</span> that can be constructed from the <span class="math inline">\(n\)</span> objects is denoted by <span class="math inline">\(P_k^n\)</span>:</p>
<span class="math display">\[ P_k^n = \frac{n!}{(n-k)!} \]</span>
</div>

</div>
<div id="combinations" class="section level3">
<h3><span class="header-section-number">2.3.2</span> Combinations</h3>

<div class="definition">
<p><span id="def:unnamed-chunk-27" class="definition"><strong>Definition 2.5  (Combination)  </strong></span>Given a set of <span class="math inline">\(n\)</span> distinct objects, any unordered subset of size <span class="math inline">\(k\)</span> of the objects is called a combination. The number of combinations <span class="math inline">\(n\)</span> of size <span class="math inline">\(k\)</span> that can be formed from <span class="math inline">\(n\)</span> distinct objects will be denoted by</p>
<span class="math display">\[ \binom{n}{k} = \frac{n!}{k!(n-k)!} = \frac{P_k^n}{k!} \]</span>
</div>

</div>
</div>
<div id="conditional-probability" class="section level2">
<h2><span class="header-section-number">2.4</span> Conditional Probability</h2>
<p>Conditional probability is the means by which probabilities are updated in the light of new information. We examine how the information <em>an event B has occurred</em> affects the probability assigned to <span class="math inline">\(A\)</span>.</p>

<div class="example">
<p><span id="exm:flipcoins" class="example"><strong>Example 2.8  (Flipping Coins)  </strong></span>We flip three different fair coins, and<br />
<span class="math display">\[ \Omega = {H H H, H H T, H T H, H T T, T H H, T H T, T T H, T T T } \]</span> with <span class="math inline">\(P(s) = 1/8\)</span> for each <span class="math inline">\(s \in \Omega\)</span>. What is the probability that the first coin comes up heads?</p>
<p><span class="math display">\[ P(\textrm{first coin heads}) = P({H H H, H H T, H T H, H T T }) = 4/8 = 1/2 \]</span></p>
<p>But suppose now that an informant tells us that exactly two of the three coins came up heads. Now what is the probability that the first coin was heads? if we know that exactly two of the coins were heads, then we know that the outcome was one of <span class="math inline">\({H H T , H T H, T H H}\)</span>.</p>
<p>Because those three outcomes should (in this case) still all be equally likely, and because only the first two correspond to the first coin being heads, we conclude the following: If we know that exactly two of the three coins are heads, then the probability that the first coin is heads is <span class="math inline">\(2/3\)</span>.</p>
<p>More precisely, we have computed a conditional probability. That is, we have determined that, conditional on knowing that exactly two coins came up heads, the conditional probability of the first coin being heads is 2/3. We write this in mathematical notation as</p>
<p><span class="math display">\[ P(\textrm{first coin heads} | \textrm{two coins heads}) = 2/3. \]</span></p>
Here the vertical bar | stands for <em>conditional on</em> or <em>given that</em>.
</div>


<div class="example">
<p><span id="exm:assembly" class="example"><strong>Example 2.9  (Assembly Lines)  </strong></span>Complex components are assembled in a plant that uses two different assembly lines, <span class="math inline">\(A\)</span> and <span class="math inline">\(A^c\)</span> . Line <span class="math inline">\(A\)</span> uses older equipment than <span class="math inline">\(A^c\)</span>, so it is somewhat slower and less reliable. <span class="math inline">\(B\)</span> are the defective components and <span class="math inline">\(B^c\)</span> are the nondefective.</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>Condition</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Line</strong></td>
<td><span class="math inline">\(B\)</span></td>
<td><span class="math inline">\(B^c\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(A\)</span></td>
<td>2</td>
<td>6</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(A^c\)</span></td>
<td>1</td>
<td>9</td>
</tr>
</tbody>
</table>
<p>The sales manager randomly selects 1 of these 18 components for a demonstration<br />
<span class="math display">\[ P(\textrm{line A component was selected}) = P(A) = \frac{N(A)}{N} = \frac{8}{18} = 0.444 \]</span></p>
<p>However, if the chosen component turns out to be defective, then the event <span class="math inline">\(B\)</span> has occurred, so the component must have been 1 of the 3 in the <span class="math inline">\(B\)</span> column of the table. Since these 3 components are equally likely among themselves after <span class="math inline">\(B\)</span> has occurred</p>
<p><span class="math display">\[ P(\textrm{line A component was selected} | \textrm{Defective}) = \frac{2}{3} = \frac{2/18}{3/18} = \frac{P(A \cap B)}{P(B)} \]</span></p>
</div>

<p>In Example <a href="probability.html#exm:assembly">2.9</a>, the conditional probability is expressed as a ratio of <strong>unconditional probabilities</strong>. The numerator is the probability of the intersection of the two events, whereas the denominator is the probability of the conditioning event <span class="math inline">\(B\)</span>. Given that <span class="math inline">\(B\)</span> has occurred, the relevant sample space is no longer <span class="math inline">\(\Omega\)</span> but consists of just outcomes in <span class="math inline">\(B\)</span>; A has occurred if and only if <em>one of the outcomes in the intersection</em> occurred, so the conditional probability of A given B is proportional to <span class="math inline">\(P(A \cap B)\)</span>. The proportionality constant <span class="math inline">\(1/P(B)\)</span> is used to ensure that the probability <span class="math inline">\(P(B | B)\)</span> of the new sample space <span class="math inline">\(B\)</span> equals 1.</p>

<div class="definition">
<p><span id="def:condprob" class="definition"><strong>Definition 2.6  (Conditional Probability)  </strong></span>Given two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, with <span class="math inline">\(P(B) &gt; 0\)</span>, the conditional probability of <span class="math inline">\(A\)</span> given <span class="math inline">\(B\)</span> is equal to</p>
<p><span class="math display">\[ P(A|B) = \frac{P(A \cap B)}{P(B)}  \]</span></p>
</div>

<p>In example <a href="probability.html#exm:flipcoins">2.8</a>, let<br />
- <span class="math inline">\(A = {H H H, H H T, H T H, H T T }\)</span> be the event that the first coin is heads<br />
- <span class="math inline">\(B = {H H T, H T H, T H H}\)</span> be the event that exactly two coins were heads</p>
<p>It follows that</p>
<p><span class="math display">\[ A \cap B = {H H T, H T H}\]</span></p>
<p>Therefore</p>
<p><span class="math display">\[ P(A|B) = \frac{P(A \cap B)}{P(B)} = \frac{P({H H T, H T H})}{P({H H T, H T H, T H H})} = \frac{2/8}{3/8} = \frac{2}{3}\]</span></p>

<div class="example">
<p><span id="exm:unnamed-chunk-28" class="example"><strong>Example 2.10  (Balanced die)  </strong></span>Suppose a balanced die is tossed in the next room. We are told that a number less than 4 was observed. What is the probability the number was either 1 or 2?</p>
</div>


<div class="example">
<p><span id="exm:unnamed-chunk-29" class="example"><strong>Example 2.11  (Two Balanced Dice v1)  </strong></span>Toss two balanced dice. Let <span class="math inline">\(A\)</span> = {sum of 5} and <span class="math inline">\(B\)</span> = {first die is <span class="math inline">\(\leq\)</span> 2}. Find <span class="math inline">\(P(A|B)\)</span></p>
</div>


<div class="example">
<p><span id="exm:unnamed-chunk-30" class="example"><strong>Example 2.12  (Two Balanced Dice v2)  </strong></span>Two balanced dice are tossed. What is the probability that the first die gives a number less than three, given that the sum is odd?</p>
</div>


<div class="example">
<p><span id="exm:unbalanced" class="example"><strong>Example 2.13  (Unbalanced Die)  </strong></span>Toss an unbalanced die with probs <span class="math inline">\(P(1)=.1\)</span>, <span class="math inline">\(P(2)=.1\)</span>, <span class="math inline">\(P(3)=.3\)</span>, <span class="math inline">\(P(4)=.2\)</span>, <span class="math inline">\(P(5)=.1\)</span>, <span class="math inline">\(P(6)=.2\)</span>. Let <span class="math inline">\(A={\geq 5}\)</span> and <span class="math inline">\(B={\geq 2}\)</span>. Find <span class="math inline">\(P(A|B)\)</span>.</p>
</div>


<div class="example">
<p><span id="exm:unnamed-chunk-31" class="example"><strong>Example 2.14  (Two Balanced Coins)  </strong></span>Two balanced coins were tossed, and it is known that at least one was a head. What is the probability that both were heads?</p>
</div>


<div class="example">
<p><span id="exm:unnamed-chunk-32" class="example"><strong>Example 2.15  (Two Cards)  </strong></span>Two cards are drawn without replacement from a standard deck. Find the probability that</p>
<ol style="list-style-type: decimal">
<li>the second is an ace, given that the first is not an ace.<br />
</li>
<li>the second is an ace.<br />
</li>
<li>the first was an ace, given that the second is an ace.</li>
</ol>
</div>


<div class="example">
<p><span id="exm:unnamed-chunk-33" class="example"><strong>Example 2.16  (Numbers in a Hat)  </strong></span>The numbers 1 to 5 are written on five slips of paper and placed in a hat. Two slips are drawn at random without replacement. What is the probability that the first number is 3, given a sum of seven?</p>
</div>


<div class="example">
<p><span id="exm:unnamed-chunk-34" class="example"><strong>Example 2.17  (One Card)  </strong></span>A card is selected at random (i.e. every card has the same probability of being chosen) from a deck of 52. What is the probability it is a red card or a face card?</p>
</div>

<p>Definition <a href="probability.html#def:condprob">2.6</a> immediately leads to the <em>multiplication formula</em></p>

<div class="definition">
<p><span id="def:multformula" class="definition"><strong>Definition 2.7  (Multiplicative Rule)  </strong></span><span class="math display">\[P(A \cap B) = P(A|B) P(B)\]</span></p>
<p>and</p>
<p><span class="math display">\[P(A \cap B) = P(B|A) P(A)\]</span></p>
</div>

<p>This allows us to compute the joint probability of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> when we are given the probability of <span class="math inline">\(B\)</span> and the conditional probability of <span class="math inline">\(A\)</span> given <span class="math inline">\(B\)</span>, and vice versa.</p>

<div class="example">
<p><span id="exm:unnamed-chunk-35" class="example"><strong>Example 2.18  (Fish in a Tank)  </strong></span>A tank has three red fish and two blue fish. Two fish are chosen at random and without replacement. What is the probability of getting</p>
<ol style="list-style-type: decimal">
<li>red fish first and then a blue fish?<br />
</li>
<li>both fish red?<br />
</li>
<li>one red fish and one blue fish?</li>
</ol>
</div>

<div id="law-of-total-probability" class="section level3">
<h3><span class="header-section-number">2.4.1</span> Law of Total Probability</h3>
<p>Recall that events <span class="math inline">\(A_1, A_2, \ldots, A_k\)</span> are mutually exclusive if no two have any common outcomes. The events are exhaustive if one <span class="math inline">\(A_i\)</span> must occure, so that<br />
<span class="math display">\[A_1 \cup A_2 \cup \cdots \cup A_k = \Omega \]</span></p>

<div class="theorem">
<span id="thm:totprob" class="theorem"><strong>Theorem 2.1  (Law of Total Probability)  </strong></span>Let <span class="math inline">\(A_1, A_2, \ldots, A_k\)</span> be mutually exclusive and exhaustive events. Then for any other event <span class="math inline">\(B\)</span>,<br />
<span class="math display">\[P(B) = P(B|A_1) P(A_1) + \cdots + P(B|A_k)P(A_k) = \sum_{i=1}^{k} P(B|A_i) P(A_i)\]</span>
</div>

<p><strong>Proof</strong>: Because the <span class="math inline">\(A_i\)</span>’s are mutually exclusive and exhaustive, if <span class="math inline">\(B\)</span> occurs it must be in conjunction with exactly one of the <span class="math inline">\(A_i\)</span>’s. That is, <span class="math inline">\(B= (A_1\textrm{ and }B)\)</span> or <span class="math inline">\(\ldots\)</span> or <span class="math inline">\((A_k\textrm{ and }B)\)</span> which is equal to <span class="math inline">\((A_1 \cap B) \cup \cdots \cup (A_k \cap B)\)</span>, where the events <span class="math inline">\((A_i \cap B)\)</span> are mutually exclusive.</p>
<div class="figure">
<img src="images/totalprob.png" />

</div>
<p>Thus we have</p>
<p><span class="math display">\[P(B) =\sum_{i=1}^{k} P(A_i \cap B) = \sum_{i=1}^{k} P(B|A_i) P(A_i) \]</span></p>

<div class="example">
<span id="exm:unnamed-chunk-36" class="example"><strong>Example 2.19  (Long Hair)  </strong></span>Suppose a class contains 60% girls and 40% boys. Suppose that 30% of the girls have long hair, and 20% of the boys have long hair. A student is chosen uniformly at random from the class. What is the probability that the chosen student will have long hair?
</div>

</div>
<div id="bayes-rule" class="section level3">
<h3><span class="header-section-number">2.4.2</span> Bayes’ Rule</h3>

<div class="theorem">
<p><span id="thm:bayesdef" class="theorem"><strong>Theorem 2.2  (Bayes’ Rule)  </strong></span>Let <span class="math inline">\(A_1, \ldots, A_k\)</span> be a collection of mutually exclusive and exhaustive events with <span class="math inline">\(P(A_i) &gt; 0\)</span> for <span class="math inline">\(i=1, \ldots, k\)</span>. Then for any other event B, for which <span class="math inline">\(P(B)&gt;0\)</span>, we have</p>
<p><span class="math display">\[ P(A_j | B) = \frac{P(A_j \cap B)}{P(B)} = \frac{P(B|A_j) P(A_j)}{\sum_{i=1}^k P(B|A_i) P(A_i)}, \quad j=1, \ldots, k   \]</span></p>
</div>

<p>The transition from the second to the third expression in Theorem <a href="probability.html#thm:bayesdef">2.2</a> rests on using the multiplication rule in the numerator and the law of total probability in the denominator.</p>

<div class="example">
<p><span id="exm:unnamed-chunk-37" class="example"><strong>Example 2.20  (Urns)  </strong></span>Suppose urn #1 has 3 red and 2 blue balls, and urn #2 has 4 red and 7 blue balls. Suppose one of the two urns is selected with probability <span class="math inline">\(1/2\)</span> each, and then one of the balls within that urn is picked uniformly at random.</p>
<ol style="list-style-type: decimal">
<li>What is the probability that urn #2 is selected at the first stage (event A) and a blue ball is selected at the second stage (event B)?<br />
</li>
<li>Compute the probability that a blue ball is obtained.<br />
</li>
<li>Now suppose we are given the information that the ball picked is blue. What is probability that we had selected urn #2?</li>
</ol>
</div>


<div class="example">
<p><span id="exm:unnamed-chunk-38" class="example"><strong>Example 2.21  (Large Bridges)  </strong></span>There are three Canadian firms which build large bridges, firm 1, firm 2, and firm 3. 20% of Canadian large bridges have been built by firm 1, 30% by firm 2, and the rest by firm 3. 5% of the bridges built by firm 1 have collapsed, while 10% of those by firm 2 have collapsed, and 30% by firm 3 have collapsed.</p>
<ol style="list-style-type: decimal">
<li>What is the probability that a bridge collapses?<br />
</li>
<li>Suppose it is reported in tomorrow’s newspaper that a large bridge has collapsed. What is the probability it was built by firm 1?</li>
</ol>
</div>

</div>
</div>
<div id="independence" class="section level2">
<h2><span class="header-section-number">2.5</span> Independence</h2>
<p>If we flip a fair coin twice, then the probability of two heads is <span class="math inline">\(1/2 \times 1/2\)</span>. We multiply the probabilities because we regard the two tosses as independent. The formal definition of independence is as follows:</p>

<div class="definition">
<span id="def:indep" class="definition"><strong>Definition 2.8  (Indepent Events)  </strong></span>Two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent if<br />
<span class="math display">\[ P(A \cap B) = P(A) P(B) \]</span>
</div>

<p>Now, because <span class="math inline">\(P(A | B) = P( A \cap B)/P(B)\)</span>, we see that <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent if and only if <span class="math inline">\(P(A | B) = P(A)\)</span> or <span class="math inline">\(P(B | A) = P(B)\)</span>, provided that <span class="math inline">\(P(A) &gt; 0\)</span> and <span class="math inline">\(P(B) &gt; 0\)</span>. Definition <a href="probability.html#def:indep">2.8</a> has the advantage that it remains valid even if <span class="math inline">\(P(B) = 0\)</span> or <span class="math inline">\(P(A) = 0\)</span>, respectively. Intuitively, events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent if neither one has any impact on the probability of the other.</p>

<div class="example">
<p><span id="exm:unnamed-chunk-39" class="example"><strong>Example 2.22  (Toss a fair coin 10 times)  </strong></span>Toss a fair coin 10 times. Let <span class="math inline">\(A = {\textrm{at least one head}}\)</span>. Let <span class="math inline">\(T_j\)</span> be the event that tails occurs on the <span class="math inline">\(j^{th}\)</span> toss. Find <span class="math inline">\(P(A)\)</span></p>
</div>


<div class="example">
<p><span id="exm:unnamed-chunk-40" class="example"><strong>Example 2.23  (Unbalance Die Revisited)  </strong></span>In Example <a href="probability.html#exm:unbalanced">2.13</a>, if <span class="math inline">\(A\)</span> is the event that the die was 5, and <span class="math inline">\(B\)</span> is the event that the coin was tails, then calculate <span class="math inline">\(P(A), P(B)\)</span> and <span class="math inline">\(P(A\cap B)\)</span></p>
</div>


</div>
</div>
<div class="footnotes">
<hr />
<ol start="2">
<li id="fn2"><p>Reproduced with permission from <a href="http://www.math.mcgill.ca/dstephens/" class="uri">http://www.math.mcgill.ca/dstephens/</a><a href="probability.html#fnref2">↩</a></p></li>
<li id="fn3"><p><a href="http://www.utstat.toronto.edu/mikevans/jeffrosenthal/book.pdf" class="uri">http://www.utstat.toronto.edu/mikevans/jeffrosenthal/book.pdf</a><a href="probability.html#fnref3">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="intro.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="discrete-random-variables-and-probability-distributions.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/sahirbhatnagar/EPIB607/edit/master/02-probability.Rmd",
"text": "Edit"
},
"download": ["epib607.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
